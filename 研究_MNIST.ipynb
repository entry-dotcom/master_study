{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3315e27c",
   "metadata": {},
   "source": [
    "[mnist実験いろいろ](https://toukei-lab.com/mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a8c698a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-16 07:53:42.346397: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/yy/y.shinozaki'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling２D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os.path as osp\n",
    "import os\n",
    "from math import pi\n",
    "import torch\n",
    "import pickle\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "#os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "HOME = osp.expanduser(\"~\")\n",
    "HOME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a18fcd-5041-4a73-b445-a3bac30b3de6",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "(MNIST参考)[ https://toukei-lab.com/mnist ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bf2ab99",
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 2 is out of bounds for array of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1086029/3980712021.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mX_validation\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m X_test /= 255\"\"\"\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m48000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mX_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36mzscore\u001b[0;34m(a, axis, ddof, nan_policy)\u001b[0m\n\u001b[1;32m   2472\u001b[0m            [-0.91611681, -0.89090508,  1.4983032 ,  0.88731639, -0.5785977 ]])\n\u001b[1;32m   2473\u001b[0m     \"\"\"\n\u001b[0;32m-> 2474\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mzmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mddof\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnan_policy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnan_policy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36mzmap\u001b[0;34m(scores, compare, axis, ddof, nan_policy)\u001b[0m\n\u001b[1;32m   2542\u001b[0m             \u001b[0misconst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_along_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_isconst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2543\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2544\u001b[0;31m         \u001b[0mmn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2545\u001b[0m         \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mddof\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0mrcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_count_reduce_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrcount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mumr_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrcount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean of empty slice.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_count_reduce_items\u001b[0;34m(arr, axis, keepdims, where)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_axis_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# TODO: Optimize case when `where` is broadcast along a non-reduction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 2 is out of bounds for array of dimension 2"
     ]
    }
   ],
   "source": [
    "# Kerasに付属の手書き数字画像データをダウンロード\n",
    "#np.random.seed(0)\n",
    "(X_train_base, labels_train_base), (X_test, labels_test) = mnist.load_data()\n",
    "X_test = dataset_second_gauss_test_3_to_4_ver2[\"test_4_imag\"]\n",
    "X_train_base = dataset_train_4_imag_ver2\n",
    "\n",
    "# Training set を学習データ（X_train, labels_train）と検証データ（X_validation, labels_validation）に8:2で分割する\n",
    "X_train,X_validation,labels_train,labels_validation = train_test_split(X_train_base,labels_train_base,test_size = 0.2)\n",
    "\n",
    "# 各画像は行列なので1次元に変換→X_train,X_validation,X_testを上書き\n",
    "\"\"\"X_train = X_train.reshape(-1,784)\n",
    "X_validation = X_validation.reshape(-1,784)\n",
    "X_test = X_test.reshape(-1,784)\"\"\"\n",
    "\n",
    "#正規化\n",
    "X_train = X_train.astype('float32')\n",
    "X_validation = X_validation.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\"\"\"X_train /= 255\n",
    "X_validation /= 255\n",
    "X_test /= 255\"\"\"\n",
    "X_train = sp.stats.zscore(X_train.reshape(48000,784),axis=1)\n",
    "X_validation = sp.stats.zscore(X_validation.reshape(12000,784),axis=1)\n",
    "X_test = sp.stats.zscore(X_test.reshape(10000,784),axis=1)\n",
    "\"\"\"X_train = X_train.reshape(48000,28,28)\n",
    "X_validation = X_validation.reshape(12000,28,28)\n",
    "X_test = X_test.reshape(10000,28,28)\"\"\"\n",
    "# labels_train, labels_validation, labels_test をダミー変数化して y_train, y_validation, y_test に格納する\n",
    "y_train = to_categorical(labels_train)\n",
    "y_validation = to_categorical(labels_validation)\n",
    "y_test = to_categorical(labels_test)\n",
    "\n",
    "# パラメータの設定\n",
    "n_features = 784\n",
    "n_hidden   = 100\n",
    "bias_init = 0.1\n",
    "\n",
    "# 学習率\n",
    "rate       = 0.003\n",
    "\n",
    "# Sequentialクラスを使ってモデルを準備する\n",
    "model = Sequential()\n",
    "\n",
    "# 隠れ層を追加\n",
    "\"\"\"model.add(Dense(32,input_shape=(28,28,1)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\"\"\"\n",
    "model.add(Dense(n_hidden,activation='relu',input_shape=(n_features,)))\n",
    "model.add(Dense(n_hidden,activation='relu'))\n",
    "model.add(Dense(n_hidden,activation='relu'))\n",
    "# 出力層を追加\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# TensorFlowのモデルを構築\n",
    "model.compile(optimizer=tf.optimizers.Adam(rate),\n",
    "              loss='categorical_crossentropy', metrics=['mae', 'accuracy'])\n",
    "\n",
    "# Early stoppingを適用してフィッティング\n",
    "log = model.fit(X_train, y_train, epochs=20, batch_size=200, verbose=True,\n",
    "                callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                     min_delta=0, patience=10, \n",
    "                                                         verbose=1)],\n",
    "                validation_data=(X_validation, y_validation))\n",
    "\n",
    "# Test dataで予測を実行。\n",
    "#pred_test = model.predict(X_test)\n",
    "#pred_test = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "pred_test = np.argmax(model.predict(X_test),axis=1)\n",
    "\n",
    "validation = (pred_test == labels_test)\n",
    "size       = validation.size\n",
    "size\n",
    "correct    = np.count_nonzero(validation)\n",
    "print(f\"{correct}/{size} correct ({correct*100/size:.3f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fed197-a4f9-4ce3-acad-763441cffd9c",
   "metadata": {},
   "source": [
    "---\n",
    "(MNIST(pytorch))[ https://qiita.com/knyrc/items/0a0092b9903b97fb41b4 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150dc427",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "04555722-1012-49b5-9666-7f4e9982b8ab",
   "metadata": {
    "code_folding": [
     0,
     46,
     50
    ],
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown activation function: step",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [247]\u001b[0m, in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(n_hidden,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m,input_shape\u001b[38;5;241m=\u001b[39m(n_features,)))\n\u001b[1;32m     40\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(n_hidden,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 41\u001b[0m model\u001b[38;5;241m.\u001b[39madd(\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_hidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstep\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# 出力層を追加\u001b[39;00m\n\u001b[1;32m     44\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m10\u001b[39m,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/layers/core.py:1161\u001b[0m, in \u001b[0;36mDense.__init__\u001b[0;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[38;5;28msuper\u001b[39m(Dense, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m   1158\u001b[0m     activity_regularizer\u001b[38;5;241m=\u001b[39mactivity_regularizer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(units) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(units, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m units\n\u001b[0;32m-> 1161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m=\u001b[39m \u001b[43mactivations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_bias \u001b[38;5;241m=\u001b[39m use_bias\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_initializer \u001b[38;5;241m=\u001b[39m initializers\u001b[38;5;241m.\u001b[39mget(kernel_initializer)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m    203\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m    204\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m    205\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/activations.py:573\u001b[0m, in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(identifier, six\u001b[38;5;241m.\u001b[39mstring_types):\n\u001b[1;32m    572\u001b[0m   identifier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(identifier)\n\u001b[0;32m--> 573\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43midentifier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(identifier, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    575\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m deserialize(identifier)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m    203\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m    204\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m    205\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/activations.py:532\u001b[0m, in \u001b[0;36mdeserialize\u001b[0;34m(name, custom_objects)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeras.activations.deserialize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    505\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeserialize\u001b[39m(name, custom_objects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    507\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns activation function given a string identifier.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \n\u001b[1;32m    509\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;124;03m      denote any defined Tensorflow activation function.\u001b[39;00m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 532\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[43m      \u001b[49m\u001b[43mprintable_module_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mactivation function\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/keras/utils/generic_utils.py:377\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    375\u001b[0m   obj \u001b[38;5;241m=\u001b[39m module_objects\u001b[38;5;241m.\u001b[39mget(object_name)\n\u001b[1;32m    376\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 377\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    378\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m printable_module_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m object_name)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# Classes passed by name are instantiated with no args, functions are\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# returned as-is.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf_inspect\u001b[38;5;241m.\u001b[39misclass(obj):\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown activation function: step"
     ]
    }
   ],
   "source": [
    "# Kerasに付属の手書き数字画像データをダウンロード(リンクの練習用)\n",
    "np.random.seed(0)\n",
    "(X_train_base, labels_train_base), (X_test, labels_test) = mnist.load_data()\n",
    "\n",
    "# Training set を学習データ（X_train, labels_train）と検証データ（X_validation, labels_validation）に8:2で分割する\n",
    "X_train,X_validation,labels_train,labels_validation = train_test_split(X_train_base,labels_train_base,test_size = 0.2)\n",
    "\n",
    "# 各画像は行列なので1次元に変換→X_train,X_validation,X_testを上書き\n",
    "X_train = X_train.reshape(-1,784)\n",
    "X_validation = X_validation.reshape(-1,784)\n",
    "X_test = X_test.reshape(-1,784)\n",
    "\n",
    "#正規化\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_validation = X_validation.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_validation /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# labels_train, labels_validation, labels_test をダミー変数化して y_train, y_validation, y_test に格納する\n",
    "y_train = to_categorical(labels_train)\n",
    "y_validation = to_categorical(labels_validation)\n",
    "y_test = to_categorical(labels_test)\n",
    "\n",
    "# パラメータの設定\n",
    "n_features = 784\n",
    "n_hidden   = 100\n",
    "bias_init = 0.1\n",
    "\n",
    "# 学習率\n",
    "rate       = 0.01\n",
    "\n",
    "# Sequentialクラスを使ってモデルを準備する\n",
    "model = Sequential()\n",
    "\n",
    "# 隠れ層を追加\n",
    "model.add(Dense(n_hidden,activation='relu',input_shape=(n_features,)))\n",
    "model.add(Dense(n_hidden,activation='relu'))\n",
    "model.add(Dense(n_hidden,activation='relu'))\n",
    "\n",
    "# 出力層を追加\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "# TensorFlowのモデルを構築\n",
    "model.compile(optimizer=tf.optimizers.Adam(rate),\n",
    "              loss='categorical_crossentropy', metrics=['mae', 'accuracy'])\n",
    "\n",
    "# Early stoppingを適用してフィッティング\n",
    "log = model.fit(X_train, y_train, epochs=3000, batch_size=100, verbose=True,\n",
    "                callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                     min_delta=0, patience=10, \n",
    "                                                         verbose=1)],\n",
    "                validation_data=(X_validation, y_validation))\n",
    "\n",
    "# Test dataで予測を実行。\n",
    "pred_test = model.predict_classes(X_test)\n",
    "\n",
    "validation = (pred_test == labels_test)\n",
    "size       = validation.size\n",
    "size\n",
    "correct    = np.count_nonzero(validation)\n",
    "print(f\"{correct}/{size} correct ({correct*100/size:.3f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a63052a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yy/y.shinozaki/研究/MNIST/MNIST_pickle/second_MNIST\n"
     ]
    }
   ],
   "source": [
    "cd MNIST_pickle/second_MNIST/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa831c94",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#　訓練データのロード\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# 0\n",
    "with open(\"second_gauss_train_0_real_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_0_real_ver2 = pickle.load(f)\n",
    "# 1\n",
    "with open(\"second_gauss_train_1_real_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_1_real_ver2 = pickle.load(f)\n",
    "with open(\"second_gauss_train_1_imag_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_1_imag_ver2 = pickle.load(f)\n",
    "# 2\n",
    "with open(\"second_gauss_train_2_real_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_2_real_ver2 = pickle.load(f)\n",
    "with open(\"second_gauss_train_2_imag_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_2_imag_ver2 = pickle.load(f)\n",
    "# 3\n",
    "with open(\"second_gauss_train_3_real_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_3_real_ver2 = pickle.load(f)\n",
    "with open(\"second_gauss_train_3_imag_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_3_imag_ver2 = pickle.load(f)\n",
    "# 4\n",
    "with open(\"second_gauss_train_4_real_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_4_real_ver2 = pickle.load(f)\n",
    "with open(\"second_gauss_train_4_imag_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_4_imag_ver2 = pickle.load(f)\n",
    "\n",
    "#　テストデータのロード\n",
    "with open(\"second_gauss_test_0_to_2_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_second_gauss_test_0_to_2_ver2 = pickle.load(f)\n",
    "with open(\"second_gauss_test_3_to_4_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_second_gauss_test_3_to_4_ver2 = pickle.load(f)\n",
    "\n",
    "#　正解(ラベル)データのロード\n",
    "with open(\"raw_mnist.pkl\",\"rb\") as f:\n",
    "     dataset_raw = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf19f239",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "240/240 [==============================] - 20s 81ms/step - loss: 0.2697 - mae: 0.0247 - accuracy: 0.9155 - val_loss: 0.1456 - val_mae: 0.0151 - val_accuracy: 0.9535\n",
      "Epoch 2/20\n",
      "240/240 [==============================] - 18s 75ms/step - loss: 0.1452 - mae: 0.0138 - accuracy: 0.9549 - val_loss: 0.1393 - val_mae: 0.0136 - val_accuracy: 0.9563\n",
      "Epoch 3/20\n",
      "240/240 [==============================] - 21s 87ms/step - loss: 0.1162 - mae: 0.0112 - accuracy: 0.9631 - val_loss: 0.1162 - val_mae: 0.0100 - val_accuracy: 0.9634\n",
      "Epoch 4/20\n",
      "240/240 [==============================] - 21s 87ms/step - loss: 0.1002 - mae: 0.0097 - accuracy: 0.9679 - val_loss: 0.1329 - val_mae: 0.0101 - val_accuracy: 0.9611\n",
      "Epoch 5/20\n",
      "240/240 [==============================] - 21s 87ms/step - loss: 0.0870 - mae: 0.0086 - accuracy: 0.9714 - val_loss: 0.1196 - val_mae: 0.0100 - val_accuracy: 0.9641\n",
      "Epoch 6/20\n",
      "240/240 [==============================] - 22s 91ms/step - loss: 0.0800 - mae: 0.0080 - accuracy: 0.9734 - val_loss: 0.1172 - val_mae: 0.0089 - val_accuracy: 0.9651\n",
      "Epoch 7/20\n",
      "240/240 [==============================] - 20s 84ms/step - loss: 0.0738 - mae: 0.0074 - accuracy: 0.9753 - val_loss: 0.1113 - val_mae: 0.0091 - val_accuracy: 0.9663\n",
      "Epoch 8/20\n",
      "240/240 [==============================] - 20s 85ms/step - loss: 0.0682 - mae: 0.0068 - accuracy: 0.9773 - val_loss: 0.1093 - val_mae: 0.0086 - val_accuracy: 0.9668\n",
      "Epoch 9/20\n",
      "240/240 [==============================] - 21s 86ms/step - loss: 0.0636 - mae: 0.0064 - accuracy: 0.9787 - val_loss: 0.1104 - val_mae: 0.0076 - val_accuracy: 0.9703\n",
      "Epoch 10/20\n",
      "240/240 [==============================] - 21s 88ms/step - loss: 0.0605 - mae: 0.0060 - accuracy: 0.9799 - val_loss: 0.1002 - val_mae: 0.0094 - val_accuracy: 0.9694\n",
      "Epoch 11/20\n",
      "240/240 [==============================] - 21s 89ms/step - loss: 0.0562 - mae: 0.0057 - accuracy: 0.9812 - val_loss: 0.1095 - val_mae: 0.0079 - val_accuracy: 0.9685\n",
      "Epoch 12/20\n",
      "240/240 [==============================] - 20s 83ms/step - loss: 0.0526 - mae: 0.0053 - accuracy: 0.9819 - val_loss: 0.1089 - val_mae: 0.0074 - val_accuracy: 0.9693\n",
      "Epoch 13/20\n",
      "240/240 [==============================] - 20s 83ms/step - loss: 0.0511 - mae: 0.0052 - accuracy: 0.9822 - val_loss: 0.1172 - val_mae: 0.0074 - val_accuracy: 0.9682\n",
      "Epoch 14/20\n",
      "240/240 [==============================] - 21s 89ms/step - loss: 0.0503 - mae: 0.0051 - accuracy: 0.9826 - val_loss: 0.1020 - val_mae: 0.0076 - val_accuracy: 0.9695\n",
      "Epoch 15/20\n",
      "240/240 [==============================] - 21s 86ms/step - loss: 0.0459 - mae: 0.0046 - accuracy: 0.9845 - val_loss: 0.1143 - val_mae: 0.0079 - val_accuracy: 0.9676\n",
      "Epoch 16/20\n",
      "240/240 [==============================] - 21s 88ms/step - loss: 0.0443 - mae: 0.0045 - accuracy: 0.9848 - val_loss: 0.1085 - val_mae: 0.0074 - val_accuracy: 0.9703\n",
      "Epoch 17/20\n",
      "240/240 [==============================] - 21s 86ms/step - loss: 0.0448 - mae: 0.0045 - accuracy: 0.9843 - val_loss: 0.1167 - val_mae: 0.0077 - val_accuracy: 0.9678\n",
      "Epoch 18/20\n",
      "240/240 [==============================] - 21s 88ms/step - loss: 0.0420 - mae: 0.0042 - accuracy: 0.9861 - val_loss: 0.1093 - val_mae: 0.0076 - val_accuracy: 0.9694\n",
      "Epoch 19/20\n",
      "240/240 [==============================] - 20s 85ms/step - loss: 0.0442 - mae: 0.0044 - accuracy: 0.9850 - val_loss: 0.1124 - val_mae: 0.0070 - val_accuracy: 0.9707\n",
      "Epoch 20/20\n",
      "240/240 [==============================] - 21s 86ms/step - loss: 0.0408 - mae: 0.0042 - accuracy: 0.9858 - val_loss: 0.1189 - val_mae: 0.0074 - val_accuracy: 0.9691\n",
      "Epoch 20: early stopping\n",
      "313/313 [==============================] - 9s 27ms/step\n",
      "9712/10000 correct (97.120%)\n"
     ]
    }
   ],
   "source": [
    "#　機械学習\n",
    "    \n",
    "#X_train_basement = np.vstack((dataset_train_0_to_2[\"second_gauss_train_0_to_2\"],dataset_train_3_to_4[\"second_gauss_train_3_to_4\"]))\n",
    "#for i in range(5,6):\n",
    "# Kerasに付属の手書き数字画像データをダウンロード\n",
    "#labels_train_base = dataset_raw[\"y_train\"]\n",
    "\n",
    "#X_train_base = np.vstack((dataset_train_0_to_2[\"second_gauss_train_0_to_2\"],dataset_train_3_to_4[\"second_gauss_train_3_to_4\"]))\n",
    "#X_test = dataset_second_gauss_test_0_to_2_ver2[\"test_4_imag\"]\n",
    "X_test = dataset_second_gauss_test_3_to_4_ver2[\"test_3_real\"]\n",
    "labels_train_base = dataset_raw[\"y_train\"]\n",
    "labels_test = dataset_raw[\"y_test\"]\n",
    "\n",
    "# Training set を学習データ（X_train, labels_train）と検証データ（X_validation, labels_validation）に8:2で分割する\n",
    "X_train,X_validation,labels_train,labels_validation = train_test_split(dataset_train_3_real_ver2,labels_train_base,test_size = 0.2) \n",
    "\n",
    "#正規化 (行ごとの正規化)\n",
    "X_train = X_train.astype('float32')\n",
    "X_validation = X_validation.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = sp.stats.zscore(X_train.reshape(48000,784),axis=1)\n",
    "X_validation = sp.stats.zscore(X_validation.reshape(12000,784),axis=1)\n",
    "X_test = sp.stats.zscore(X_test.reshape(10000,784),axis=1)\n",
    "\"\"\"\n",
    "X_train = preprocessing.minmax_scale(X_train.reshape(48000,784),axis=1)\n",
    "X_validation = preprocessing.minmax_scale(X_validation.reshape(12000,784),axis=1)\n",
    "X_test = preprocessing.minmax_scale(X_test.reshape(10000,784),axis=1)\n",
    "\"\"\"\n",
    "\"\"\"y_train = to_categorical(labels_train)\n",
    "y_validation = to_categorical(labels_validation)\n",
    "y_test = to_categorical(labels_test)    \n",
    "\"\"\"\n",
    "#　さらにreshape\n",
    "X_train = X_train.reshape(48000,28,28)\n",
    "X_validation = X_validation.reshape(12000,28,28)\n",
    "X_test = X_test.reshape(10000,28,28)\n",
    "y_train = to_categorical(labels_train)\n",
    "y_validation = to_categorical(labels_validation)\n",
    "y_test = to_categorical(labels_test)    \n",
    "    \n",
    "# パラメータの設定\n",
    "n_features = 784\n",
    "n_hidden   = 100\n",
    "bias_init = 0.1\n",
    "\n",
    "# 学習率\n",
    "rate       = 0.003\n",
    "\n",
    "# Sequentialクラスを使ってモデルを準備する\n",
    "model = Sequential()\n",
    "\n",
    "# 隠れ層を追加\n",
    "model.add(Dense(32,input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "# 出力層を追加\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# TensorFlowのモデルを構築\n",
    "model.compile(optimizer=tf.optimizers.Adam(rate),\n",
    "                  loss='categorical_crossentropy', metrics=['mae', 'accuracy'])\n",
    "\n",
    "# Early stoppingを適用してフィッティング\n",
    "log = model.fit(X_train, y_train, epochs=20, batch_size=200, verbose=True,\n",
    "                callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                       min_delta=0, patience=10, \n",
    "                                                          verbose=1)],\n",
    "                validation_data=(X_validation, y_validation))\n",
    "\n",
    "hist_df = pd.DataFrame(log.history)\n",
    "hist_df.to_csv(\"history_3_real.csv\")\n",
    "\n",
    "# モデルを保存\n",
    "model.save_weights(HOME+\"/研究/MNIST/MNIST_models/checkpoint_3_real\")\n",
    "# Test dataで予測を実行。\n",
    "pred_test = np.argmax(model.predict(X_test), axis=-1)\n",
    "\n",
    "validation = (pred_test == labels_test)\n",
    "size       = validation.size\n",
    "size\n",
    "correct    = np.count_nonzero(validation)\n",
    "print(f\"{correct}/{size} correct ({correct*100/size:.3f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0fcaa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_csv = pd.read_csv('history_0_real.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0109af4a",
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(history, \n",
    "                save_graph_img_path, \n",
    "                fig_size_width, \n",
    "                fig_size_height, \n",
    "                lim_font_size):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "   \n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    # グラフ表示\n",
    "    plt.figure(figsize=(fig_size_width, fig_size_height))\n",
    "    \n",
    "    \n",
    "    #plt.rcParams['font.family'] = 'Times New Roman'\n",
    "    plt.rcParams['font.size'] = 50  # 全体のフォント\n",
    "    plt.rcParams['xtick.direction'] = 'in'\n",
    "    plt.rcParams['ytick.direction'] = 'in'\n",
    "    #plt.subplot(121)\n",
    "    plt.grid()\n",
    "    plt.axis([0,20, 0.9,1])\n",
    "   \n",
    "    plt.xticks(np.arange(0,22,4))\n",
    "    plt.xlim([-0.5,22])\n",
    "    plt.ylim([0.92,1.0])\n",
    "    \n",
    "    \n",
    "    # plot accuracy values\n",
    "    plt.plot(epochs, acc, color = \"blue\", linestyle = \"solid\", label = 'test acc', linewidth=5)\n",
    "    plt.plot(epochs, val_acc, color = \"green\", linestyle = \"solid\", label= 'valid acc', linewidth=5)\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig(save_graph_img_path)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close() # バッファ解放"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091c67bc",
   "metadata": {},
   "source": [
    "(MNISTモデルの使い方)[　https://qiita.com/zunda_pixel/items/6178855310302efabfcc　]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "929b2b2f",
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_78 (Dense)            (None, 28, 28, 32)        64        \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 26, 26, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_39 (MaxPoolin  (None, 13, 13, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 13, 13, 32)        0         \n",
      "                                                                 \n",
      " flatten_39 (Flatten)        (None, 5408)              0         \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 10)                54090     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 63,402\n",
      "Trainable params: 63,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "8487/10000 correct (84.870%)\n"
     ]
    }
   ],
   "source": [
    "# 学習率\n",
    "rate       = 0.003\n",
    "\n",
    "# テストデータ準備\n",
    "X_test = dataset_second_gauss_test_3_to_4_ver2[\"test_3_real\"]\n",
    "X_test = X_test.astype('float32')\n",
    "X_test = sp.stats.zscore(X_test.reshape(10000,784),axis=1)\n",
    "X_test = sp.stats.zscore(X_test.reshape(10000,28,28))\n",
    "                         \n",
    "# Sequentialクラスを使ってモデルを準備する\n",
    "model = Sequential()\n",
    "# 隠れ層を追加\n",
    "model.add(Dense(32,input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "# 出力層を追加\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# TensorFlowのモデルを構築\n",
    "model.compile(optimizer=tf.optimizers.Adam(rate),loss='categorical_crossentropy', metrics=['mae', 'accuracy'])\n",
    "model.summary()\n",
    "model.load_weights(HOME+\"/研究/MNIST/MNIST_models/checkpoint_3_real\")\n",
    "\n",
    "pred_test = np.argmax(model.predict(X_test), axis=-1)\n",
    "\n",
    "validation = (pred_test == labels_test)\n",
    "size       = validation.size\n",
    "size\n",
    "correct    = np.count_nonzero(validation)\n",
    "print(f\"{correct}/{size} correct ({correct*100/size:.3f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b88d960",
   "metadata": {},
   "source": [
    "(参考)[ https://qiita.com/fukuit/items/b3fa460577a0ea139c88 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dda32538-aa73-4277-8f1b-c9aa75afa68b",
   "metadata": {
    "code_folding": [],
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "480/480 [==============================] - 18s 37ms/step - loss: 0.1949 - categorical_crossentropy: 0.1949 - accuracy: 0.9399 - val_loss: 0.0622 - val_categorical_crossentropy: 0.0622 - val_accuracy: 0.9811\n",
      "Epoch 2/20\n",
      "480/480 [==============================] - 26s 55ms/step - loss: 0.0721 - categorical_crossentropy: 0.0721 - accuracy: 0.9778 - val_loss: 0.0474 - val_categorical_crossentropy: 0.0474 - val_accuracy: 0.9857\n",
      "Epoch 3/20\n",
      "480/480 [==============================] - 22s 46ms/step - loss: 0.0593 - categorical_crossentropy: 0.0593 - accuracy: 0.9812 - val_loss: 0.0354 - val_categorical_crossentropy: 0.0354 - val_accuracy: 0.9883\n",
      "Epoch 4/20\n",
      "480/480 [==============================] - 20s 42ms/step - loss: 0.0527 - categorical_crossentropy: 0.0527 - accuracy: 0.9839 - val_loss: 0.0448 - val_categorical_crossentropy: 0.0448 - val_accuracy: 0.9852\n",
      "Epoch 5/20\n",
      "480/480 [==============================] - 22s 46ms/step - loss: 0.0462 - categorical_crossentropy: 0.0462 - accuracy: 0.9858 - val_loss: 0.0453 - val_categorical_crossentropy: 0.0453 - val_accuracy: 0.9868\n",
      "Epoch 6/20\n",
      "480/480 [==============================] - 28s 59ms/step - loss: 0.0456 - categorical_crossentropy: 0.0456 - accuracy: 0.9851 - val_loss: 0.0461 - val_categorical_crossentropy: 0.0461 - val_accuracy: 0.9851\n",
      "Epoch 7/20\n",
      "480/480 [==============================] - 30s 62ms/step - loss: 0.0423 - categorical_crossentropy: 0.0423 - accuracy: 0.9864 - val_loss: 0.0404 - val_categorical_crossentropy: 0.0404 - val_accuracy: 0.9879\n",
      "Epoch 8/20\n",
      "480/480 [==============================] - 23s 47ms/step - loss: 0.0412 - categorical_crossentropy: 0.0412 - accuracy: 0.9869 - val_loss: 0.0412 - val_categorical_crossentropy: 0.0412 - val_accuracy: 0.9875\n",
      "Epoch 9/20\n",
      "480/480 [==============================] - 21s 43ms/step - loss: 0.0391 - categorical_crossentropy: 0.0391 - accuracy: 0.9873 - val_loss: 0.0369 - val_categorical_crossentropy: 0.0369 - val_accuracy: 0.9892\n",
      "Epoch 10/20\n",
      "480/480 [==============================] - 27s 56ms/step - loss: 0.0366 - categorical_crossentropy: 0.0366 - accuracy: 0.9887 - val_loss: 0.0349 - val_categorical_crossentropy: 0.0349 - val_accuracy: 0.9902\n",
      "Epoch 11/20\n",
      "480/480 [==============================] - 27s 56ms/step - loss: 0.0357 - categorical_crossentropy: 0.0357 - accuracy: 0.9882 - val_loss: 0.0375 - val_categorical_crossentropy: 0.0375 - val_accuracy: 0.9894\n",
      "Epoch 12/20\n",
      "480/480 [==============================] - 25s 52ms/step - loss: 0.0324 - categorical_crossentropy: 0.0324 - accuracy: 0.9896 - val_loss: 0.0383 - val_categorical_crossentropy: 0.0383 - val_accuracy: 0.9893\n",
      "Epoch 13/20\n",
      "480/480 [==============================] - 21s 45ms/step - loss: 0.0324 - categorical_crossentropy: 0.0324 - accuracy: 0.9897 - val_loss: 0.0368 - val_categorical_crossentropy: 0.0368 - val_accuracy: 0.9906\n",
      "Epoch 14/20\n",
      "480/480 [==============================] - 22s 46ms/step - loss: 0.0310 - categorical_crossentropy: 0.0310 - accuracy: 0.9900 - val_loss: 0.0385 - val_categorical_crossentropy: 0.0385 - val_accuracy: 0.9906\n",
      "Epoch 15/20\n",
      "480/480 [==============================] - 27s 57ms/step - loss: 0.0309 - categorical_crossentropy: 0.0309 - accuracy: 0.9897 - val_loss: 0.0414 - val_categorical_crossentropy: 0.0414 - val_accuracy: 0.9894\n",
      "Epoch 16/20\n",
      "480/480 [==============================] - 27s 56ms/step - loss: 0.0292 - categorical_crossentropy: 0.0292 - accuracy: 0.9910 - val_loss: 0.0390 - val_categorical_crossentropy: 0.0390 - val_accuracy: 0.9905\n",
      "Epoch 17/20\n",
      "480/480 [==============================] - 24s 50ms/step - loss: 0.0304 - categorical_crossentropy: 0.0304 - accuracy: 0.9904 - val_loss: 0.0461 - val_categorical_crossentropy: 0.0461 - val_accuracy: 0.9883\n",
      "Epoch 18/20\n",
      "480/480 [==============================] - 22s 46ms/step - loss: 0.0278 - categorical_crossentropy: 0.0278 - accuracy: 0.9904 - val_loss: 0.0440 - val_categorical_crossentropy: 0.0440 - val_accuracy: 0.9880\n",
      "Epoch 19/20\n",
      "480/480 [==============================] - 24s 49ms/step - loss: 0.0275 - categorical_crossentropy: 0.0275 - accuracy: 0.9913 - val_loss: 0.0434 - val_categorical_crossentropy: 0.0434 - val_accuracy: 0.9889\n",
      "Epoch 20/20\n",
      "480/480 [==============================] - 25s 53ms/step - loss: 0.0247 - categorical_crossentropy: 0.0247 - accuracy: 0.9915 - val_loss: 0.0410 - val_categorical_crossentropy: 0.0410 - val_accuracy: 0.9889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/yy/y.shinozaki/研究/MNIST/second_MNIST/models/second_mnist_raw_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/yy/y.shinozaki/研究/MNIST/second_MNIST/models/second_mnist_raw_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 5ms/step\n",
      "9914/10000 correct (99.140%)\n"
     ]
    }
   ],
   "source": [
    "#　普通のMINIST\n",
    "np.random.seed(0)\n",
    "(X_train_base, labels_train_base), (X_test, labels_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "# Training set を学習データ（X_train, labels_train）と検証データ（X_validation, labels_validation）に8:2で分割する\n",
    "X_train,X_validation,labels_train,labels_validation = train_test_split(X_train_base,labels_train_base,test_size = 0.2)\n",
    "\n",
    "# 各画像は行列なので1次元に変換→X_train,X_validation,X_testを上書き\n",
    "#X_train = X_train.reshape(-1,784)\n",
    "#X_validation = X_validation.reshape(-1,784)\n",
    "#X_test = X_test.reshape(-1,784)\n",
    "\n",
    "#正規化\n",
    "X_train = X_train.astype('float32')\n",
    "X_validation = X_validation.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_validation /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# labels_train, labels_validation, labels_test をダミー変数化して y_train, y_validation, y_test に格納する\n",
    "y_train = to_categorical(labels_train)\n",
    "y_validation = to_categorical(labels_validation)\n",
    "y_test = to_categorical(labels_test)\n",
    "\n",
    "\n",
    "# パラメータの設定\n",
    "n_features = 784\n",
    "n_hidden   = 100\n",
    "bias_init = 0.1\n",
    "\n",
    "# 学習率\n",
    "rate       = 0.005\n",
    "\n",
    "# Sequentialクラスを使ってモデルを準備する\n",
    "model = Sequential()\n",
    "\n",
    "# 隠れ層を追加\n",
    "#model.add(Dense(1,kernel_regularizer=keras.regularizers.l2(rate),input_shape=(28, 28, 1)))\n",
    "#model.add(Conv2D(1, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64,kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32,kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "# 出力層を追加\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# TensorFlowのモデルを構築\n",
    "model.compile(optimizer=tf.optimizers.Adam(rate),\n",
    "              loss='categorical_crossentropy', metrics=['categorical_crossentropy', 'accuracy'])\n",
    "\n",
    "# Early stoppingを適用してフィッティング\n",
    "log1 = model.fit(X_train, y_train, epochs=20, batch_size=100, verbose=True,\n",
    "                #callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                  #                                min_delta=0, patience=10, \n",
    "                    #                                     verbose=1)],\n",
    "                validation_data=(X_validation, y_validation))\n",
    "\n",
    "# モデルを保存\n",
    "model.save(HOME+\"/研究/MNIST/second_MNIST/models/second_mnist_raw_model\")\n",
    "\n",
    "# Test dataで予測を実行。\n",
    "pred_test = np.argmax(model.predict(X_test), axis=-1)\n",
    "\n",
    "validation = (pred_test == labels_test)\n",
    "size       = validation.size\n",
    "size\n",
    "correct    = np.count_nonzero(validation)\n",
    "print(f\"{correct}/{size} correct ({correct*100/size:.3f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e24f2c8b",
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 36s 75ms/step - loss: 0.1958 - categorical_crossentropy: 0.1958 - accuracy: 0.9418\n",
      "categorical_crossentropy: 11.49%\n",
      "480/480 [==============================] - 38s 78ms/step - loss: 0.1989 - categorical_crossentropy: 0.1989 - accuracy: 0.9394\n",
      "categorical_crossentropy: 8.33%\n",
      "480/480 [==============================] - 36s 74ms/step - loss: 0.2002 - categorical_crossentropy: 0.2002 - accuracy: 0.9407\n",
      "categorical_crossentropy: 9.22%\n",
      "480/480 [==============================] - 32s 67ms/step - loss: 0.2044 - categorical_crossentropy: 0.2044 - accuracy: 0.9395\n",
      "categorical_crossentropy: 10.30%\n",
      "480/480 [==============================] - 37s 76ms/step - loss: 0.2010 - categorical_crossentropy: 0.2010 - accuracy: 0.9406\n",
      "categorical_crossentropy: 9.54%\n",
      "9.78% (+/- 1.06%)\n"
     ]
    }
   ],
   "source": [
    "#　普通のMINIST(K-fold cross validationあり)\n",
    "np.random.seed(0)\n",
    "#(X_train_base, labels_train_base), (X_test, labels_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "# Training set を学習データ（X_train, labels_train）と検証データ（X_validation, labels_validation）に8:2で分割する\n",
    "(X_train,y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 各画像は行列なので1次元に変換→X_train,X_validation,X_testを上書き\n",
    "#X_train = X_train.reshape(-1,784)\n",
    "#X_validation = X_validation.reshape(-1,784)\n",
    "#X_test = X_test.reshape(-1,784)\n",
    "\n",
    "#正規化\n",
    "X_train = X_train.astype('float32')\n",
    "#X_validation = X_validation.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "#X_validation /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# labels_train, labels_validation, labels_test をダミー変数化して y_train, y_validation, y_test に格納する\n",
    "#y_train = to_categorical(labels_train)\n",
    "#y_validation = to_categorical(labels_validation)\n",
    "#y_test = to_categorical(labels_test)\n",
    "\n",
    "\n",
    "# パラメータの設定\n",
    "n_features = 784\n",
    "n_hidden   = 100\n",
    "bias_init = 0.1\n",
    "\n",
    "# 学習率\n",
    "rate       = 0.005\n",
    "\n",
    "# X-fold cross validationを定義\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "cvscores = []\n",
    "\n",
    "for train, test in kfold.split(X_train, y_train):\n",
    "    \n",
    "    # Sequentialクラスを使ってモデルを準備する\n",
    "    model = Sequential()\n",
    "\n",
    "    # 隠れ層を追加\n",
    "    model.add(Conv2D(32,kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    # 出力層を追加\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    # TensorFlowのモデルを構築\n",
    "    model.compile(optimizer=tf.optimizers.Adam(rate),\n",
    "                  loss='categorical_crossentropy', metrics=['categorical_crossentropy', 'accuracy'])\n",
    "\n",
    "    # Early stoppingを適用してフィッティング\n",
    "    log1 = model.fit(X_train[train], keras.utils.to_categorical(y_train[train],10), epochs=1, batch_size=100, verbose=1)\n",
    "\n",
    "    # Test dataで予測を実行。\n",
    "    # Evaluate\n",
    "    scores = model.evaluate(X_train[test], keras.utils.to_categorical(y_train[test], 10), verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "    \"\"\"\n",
    "    pred_test = np.argmax(model.predict(X_test), axis=-1)\n",
    "\n",
    "    validation = (pred_test == labels_test)\n",
    "    size       = validation.size\n",
    "    size\n",
    "    correct    = np.count_nonzero(validation)\n",
    "    print(f\"{correct}/{size} correct ({correct*100/size:.3f}%)\")\n",
    "    \"\"\"\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1edbe11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mse</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.202244</td>\n",
       "      <td>0.009082</td>\n",
       "      <td>0.939500</td>\n",
       "      <td>0.093253</td>\n",
       "      <td>0.004388</td>\n",
       "      <td>0.970833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.089231</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.973000</td>\n",
       "      <td>0.070742</td>\n",
       "      <td>0.003324</td>\n",
       "      <td>0.978500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.072009</td>\n",
       "      <td>0.003373</td>\n",
       "      <td>0.978083</td>\n",
       "      <td>0.069125</td>\n",
       "      <td>0.003337</td>\n",
       "      <td>0.978500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.058736</td>\n",
       "      <td>0.002866</td>\n",
       "      <td>0.980812</td>\n",
       "      <td>0.058697</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>0.982667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.051509</td>\n",
       "      <td>0.002512</td>\n",
       "      <td>0.983583</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>0.981000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.045185</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.985729</td>\n",
       "      <td>0.053284</td>\n",
       "      <td>0.002510</td>\n",
       "      <td>0.982750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.041567</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>0.985979</td>\n",
       "      <td>0.052448</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.983833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.040123</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.986750</td>\n",
       "      <td>0.061745</td>\n",
       "      <td>0.002859</td>\n",
       "      <td>0.981583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.033918</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>0.988437</td>\n",
       "      <td>0.059825</td>\n",
       "      <td>0.002729</td>\n",
       "      <td>0.982833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.029331</td>\n",
       "      <td>0.001506</td>\n",
       "      <td>0.989937</td>\n",
       "      <td>0.068490</td>\n",
       "      <td>0.003018</td>\n",
       "      <td>0.980833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.031723</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>0.989625</td>\n",
       "      <td>0.057445</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>0.983833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.028105</td>\n",
       "      <td>0.001462</td>\n",
       "      <td>0.990271</td>\n",
       "      <td>0.061199</td>\n",
       "      <td>0.002559</td>\n",
       "      <td>0.983333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.028121</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.990354</td>\n",
       "      <td>0.055638</td>\n",
       "      <td>0.002302</td>\n",
       "      <td>0.985500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.025807</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>0.990687</td>\n",
       "      <td>0.060537</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>0.983250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.023066</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.992146</td>\n",
       "      <td>0.059171</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>0.984667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.024795</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>0.991208</td>\n",
       "      <td>0.057057</td>\n",
       "      <td>0.002306</td>\n",
       "      <td>0.985500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.021014</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.992854</td>\n",
       "      <td>0.065957</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>0.983333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.019675</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.992833</td>\n",
       "      <td>0.064758</td>\n",
       "      <td>0.002587</td>\n",
       "      <td>0.984083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.022532</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.992375</td>\n",
       "      <td>0.064856</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>0.984833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.020836</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.993271</td>\n",
       "      <td>0.061373</td>\n",
       "      <td>0.002434</td>\n",
       "      <td>0.985333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss       mse  accuracy  val_loss   val_mse  val_accuracy\n",
       "0   0.202244  0.009082  0.939500  0.093253  0.004388      0.970833\n",
       "1   0.089231  0.004150  0.973000  0.070742  0.003324      0.978500\n",
       "2   0.072009  0.003373  0.978083  0.069125  0.003337      0.978500\n",
       "3   0.058736  0.002866  0.980812  0.058697  0.002735      0.982667\n",
       "4   0.051509  0.002512  0.983583  0.057692  0.002794      0.981000\n",
       "5   0.045185  0.002187  0.985729  0.053284  0.002510      0.982750\n",
       "6   0.041567  0.002119  0.985979  0.052448  0.002493      0.983833\n",
       "7   0.040123  0.002018  0.986750  0.061745  0.002859      0.981583\n",
       "8   0.033918  0.001737  0.988437  0.059825  0.002729      0.982833\n",
       "9   0.029331  0.001506  0.989937  0.068490  0.003018      0.980833\n",
       "10  0.031723  0.001628  0.989625  0.057445  0.002554      0.983833\n",
       "11  0.028105  0.001462  0.990271  0.061199  0.002559      0.983333\n",
       "12  0.028121  0.001440  0.990354  0.055638  0.002302      0.985500\n",
       "13  0.025807  0.001375  0.990687  0.060537  0.002608      0.983250\n",
       "14  0.023066  0.001198  0.992146  0.059171  0.002415      0.984667\n",
       "15  0.024795  0.001323  0.991208  0.057057  0.002306      0.985500\n",
       "16  0.021014  0.001102  0.992854  0.065957  0.002669      0.983333\n",
       "17  0.019675  0.001044  0.992833  0.064758  0.002587      0.984083\n",
       "18  0.022532  0.001172  0.992375  0.064856  0.002431      0.984833\n",
       "19  0.020836  0.001061  0.993271  0.061373  0.002434      0.985333"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(log1.history).to_csv(HOME+\"/研究/MNIST/second_MNIST/second_mnist_raw_log.csv\",index=False)\n",
    "a = pd.read_csv(HOME+\"/研究/MNIST/second_MNIST/second_mnist_raw_log.csv\")\n",
    "a\n",
    "# 9830/10000 correct (98.300%)\n",
    "#9847/10000 correct (98.470%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01acb2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yy/y.shinozaki/研究/MNIST/MNIST_pickle/second_MNIST\n"
     ]
    }
   ],
   "source": [
    "cd MNIST_pickle/second_MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "aa4225da",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 9層のバージョン\n",
    "\"\"\"from sklearn import preprocessing\n",
    "import pickle\n",
    "\n",
    "#　訓練データのロード\n",
    "# 0\n",
    "with open(\"second_gauss_train_0_real_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_0_real_ver2 = pickle.load(f)\n",
    "# 1\n",
    "with open(\"second_gauss_train_1_real_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_1_real_ver2 = pickle.load(f)\n",
    "with open(\"second_gauss_train_1_imag_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_1_imag_ver2 = pickle.load(f)\n",
    "# 2\n",
    "with open(\"second_gauss_train_2_real_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_2_real_ver2 = pickle.load(f)\n",
    "with open(\"second_gauss_train_2_imag_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_2_imag_ver2 = pickle.load(f)\n",
    "# 3\n",
    "with open(\"second_gauss_train_3_real_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_3_real_ver2 = pickle.load(f)\n",
    "with open(\"second_gauss_train_3_imag_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_3_imag_ver2 = pickle.load(f)\n",
    "# 4\n",
    "with open(\"second_gauss_train_4_real_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_4_real_ver2 = pickle.load(f)\n",
    "with open(\"second_gauss_train_4_imag_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_4_imag_ver2 = pickle.load(f)\n",
    "\n",
    "#　テストデータのロード\n",
    "with open(\"second_gauss_test_0_to_2_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_second_gauss_test_0_to_2_ver2 = pickle.load(f)\n",
    "with open(\"second_gauss_test_3_to_4_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_second_gauss_test_3_to_4_ver2 = pickle.load(f)\n",
    "\n",
    "#　正解(ラベル)データのロード\n",
    "with open(\"raw_mnist.pkl\",\"rb\") as f:\n",
    "     dataset_raw = pickle.load(f)\n",
    "\n",
    "###　訓練データ\n",
    "#　reshapeと型変換\n",
    "dataset_train_0_real_ver2 = dataset_train_0_real_ver2.astype('float32').reshape(60000,784)\n",
    "dataset_train_1_real_ver2 = dataset_train_1_real_ver2.astype('float32').reshape(60000,784)\n",
    "dataset_train_1_imag_ver2 = dataset_train_1_imag_ver2.astype('float32').reshape(60000,784)\n",
    "dataset_train_2_real_ver2 = dataset_train_2_real_ver2.astype('float32').reshape(60000,784)\n",
    "dataset_train_2_imag_ver2 = dataset_train_2_imag_ver2.astype('float32').reshape(60000,784)\n",
    "dataset_train_3_real_ver2 = dataset_train_3_real_ver2.astype('float32').reshape(60000,784)\n",
    "dataset_train_3_imag_ver2 = dataset_train_3_imag_ver2.astype('float32').reshape(60000,784)\n",
    "dataset_train_4_real_ver2 = dataset_train_4_real_ver2.astype('float32').reshape(60000,784)\n",
    "dataset_train_4_imag_ver2 = dataset_train_4_imag_ver2.astype('float32').reshape(60000,784)\n",
    "#　正規化\n",
    "dataset_train_0_real_ver2 = sp.stats.zscore(dataset_train_0_real_ver2,axis=None)\n",
    "dataset_train_1_real_ver2 = sp.stats.zscore(dataset_train_1_real_ver2,axis=None)\n",
    "dataset_train_1_imag_ver2 = sp.stats.zscore(dataset_train_1_imag_ver2,axis=None)\n",
    "dataset_train_2_real_ver2 = sp.stats.zscore(dataset_train_2_real_ver2,axis=None)\n",
    "dataset_train_2_imag_ver2 = sp.stats.zscore(dataset_train_2_imag_ver2,axis=None)\n",
    "dataset_train_3_real_ver2 = sp.stats.zscore(dataset_train_3_real_ver2,axis=None)\n",
    "dataset_train_3_imag_ver2 = sp.stats.zscore(dataset_train_3_imag_ver2,axis=None)\n",
    "dataset_train_4_real_ver2 = sp.stats.zscore(dataset_train_4_real_ver2,axis=None)\n",
    "dataset_train_4_imag_ver2 = sp.stats.zscore(dataset_train_4_imag_ver2,axis=None)\n",
    "X_train_base = np.stack((dataset_train_0_real_ver2.reshape(60000,28,28), dataset_train_1_real_ver2.reshape(60000,28,28),\n",
    "                         dataset_train_1_imag_ver2.reshape(60000,28,28), dataset_train_2_real_ver2.reshape(60000,28,28), \n",
    "                         dataset_train_2_imag_ver2.reshape(60000,28,28), dataset_train_3_real_ver2.reshape(60000,28,28), \n",
    "                         dataset_train_3_imag_ver2.reshape(60000,28,28),dataset_train_4_real_ver2.reshape(60000,28,28),\n",
    "                         dataset_train_4_imag_ver2.reshape(60000,28,28)),axis=3)\n",
    "\"\"\"\n",
    "for i in range(2*Q+1):\n",
    "    second_gauss_train[i] = sp.stats.zscore(second_gauss_train[i],axis=None)\n",
    "    second_gauss_test[i] = sp.stats.zscore(second_gauss_test[i],axis=None)\n",
    "    \n",
    "X_train_base =  np.stack((second_gauss_train[0].reshape(60000,28,28),second_gauss_train[1].reshape(60000,28,28),\n",
    "                          second_gauss_train[2].reshape(60000,28,28),second_gauss_train[3].reshape(60000,28,28),\n",
    "                          second_gauss_train[4].reshape(60000,28,28),second_gauss_train[5].reshape(60000,28,28),\n",
    "                          second_gauss_train[6].reshape(60000,28,28),second_gauss_train[7].reshape(60000,28,28),\n",
    "                          second_gauss_train[8].reshape(60000,28,28)),axis=3)\n",
    "                   \n",
    "X_test = np.stack((second_gauss_test[0].reshape(10000,28,28),second_gauss_test[1].reshape(10000,28,28),\n",
    "                   second_gauss_test[2].reshape(10000,28,28),second_gauss_test[3].reshape(10000,28,28),\n",
    "                   second_gauss_test[4].reshape(10000,28,28),second_gauss_test[5].reshape(10000,28,28),\n",
    "                   second_gauss_test[6].reshape(10000,28,28),second_gauss_test[7].reshape(10000,28,28),\n",
    "                   second_gauss_test[8].reshape(10000,28,28)),axis=3)\n",
    "\n",
    "\n",
    "\"\"\"###\n",
    "#　テストデータのロード\n",
    "with open(\"second_gauss_test_0_to_2_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_second_gauss_test_0_to_2_ver2 = pickle.load(f)\n",
    "with open(\"second_gauss_test_3_to_4_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_second_gauss_test_3_to_4_ver2 = pickle.load(f)\n",
    "\n",
    "# reshapeと型変換\n",
    "test_0_real = dataset_second_gauss_test_0_to_2_ver2[\"test_0_real\"].astype('float32').reshape(10000,784)\n",
    "test_1_real = dataset_second_gauss_test_0_to_2_ver2[\"test_1_real\"].astype('float32').reshape(10000,784)\n",
    "test_1_imag = dataset_second_gauss_test_0_to_2_ver2[\"test_1_imag\"].astype('float32').reshape(10000,784)\n",
    "test_2_real = dataset_second_gauss_test_0_to_2_ver2[\"test_2_real\"].astype('float32').reshape(10000,784)\n",
    "test_2_imag = dataset_second_gauss_test_0_to_2_ver2[\"test_2_imag\"].astype('float32').reshape(10000,784)\n",
    "test_3_real = dataset_second_gauss_test_3_to_4_ver2[\"test_3_real\"].astype('float32').reshape(10000,784)\n",
    "test_3_imag = dataset_second_gauss_test_3_to_4_ver2[\"test_3_imag\"].astype('float32').reshape(10000,784)\n",
    "test_4_real = dataset_second_gauss_test_3_to_4_ver2[\"test_4_real\"].astype('float32').reshape(10000,784)\n",
    "test_4_imag = dataset_second_gauss_test_3_to_4_ver2[\"test_4_imag\"].astype('float32').reshape(10000,784)\n",
    "# 行ごとの正規化\n",
    "test_0_real = sp.stats.zscore(test_0_real,axis=None)\n",
    "test_1_real = sp.stats.zscore(test_1_real,axis=None)\n",
    "test_1_imag = sp.stats.zscore(test_1_imag,axis=None)\n",
    "test_2_real = sp.stats.zscore(test_2_real,axis=None)\n",
    "test_2_imag = sp.stats.zscore(test_2_imag,axis=None)\n",
    "test_3_real = sp.stats.zscore(test_3_real,axis=None)\n",
    "test_3_imag = sp.stats.zscore(test_3_imag,axis=None)\n",
    "test_4_real = sp.stats.zscore(test_4_real,axis=None)\n",
    "test_4_imag = sp.stats.zscore(test_4_imag,axis=None)\n",
    "X_test = np.stack((test_0_real.reshape(10000,28,28), test_1_real.reshape(10000,28,28), test_1_imag.reshape(10000,28,28), \n",
    "                   test_2_real.reshape(10000,28,28), test_2_imag.reshape(10000,28,28), test_3_real.reshape(10000,28,28), \n",
    "                   test_3_imag.reshape(10000,28,28), test_4_real.reshape(10000,28,28),test_4_imag.reshape(10000,28,28)),axis=3)\n",
    "\n",
    "\"\"\"\n",
    "#　正解(ラベル)データのロード\n",
    "with open(\"raw_mnist.pkl\",\"rb\") as f:\n",
    "     dataset_raw = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1be0fcc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 60000, 784)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0df109e",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# 5層のバージョン(Qごとの絶対値)\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "\n",
    "#　訓練データのロード\n",
    "# 0\n",
    "with open(\"second_gauss_train_0_real_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_0_real_ver2 = pickle.load(f)\n",
    "# 1\n",
    "with open(\"second_gauss_train_1_real_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_1_real_ver2 = pickle.load(f)\n",
    "with open(\"second_gauss_train_1_imag_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_1_imag_ver2 = pickle.load(f)\n",
    "# 2\n",
    "with open(\"second_gauss_train_2_real_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_2_real_ver2 = pickle.load(f)\n",
    "with open(\"second_gauss_train_2_imag_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_2_imag_ver2 = pickle.load(f)\n",
    "# 3\n",
    "with open(\"second_gauss_train_3_real_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_3_real_ver2 = pickle.load(f)\n",
    "with open(\"second_gauss_train_3_imag_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_3_imag_ver2 = pickle.load(f)\n",
    "# 4\n",
    "with open(\"second_gauss_train_4_real_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_4_real_ver2 = pickle.load(f)\n",
    "with open(\"second_gauss_train_4_imag_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_4_imag_ver2 = pickle.load(f)\n",
    "\n",
    "#　テストデータのロード\n",
    "with open(\"second_gauss_test_0_to_2_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_second_gauss_test_0_to_2_ver2 = pickle.load(f)\n",
    "with open(\"second_gauss_test_3_to_4_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_second_gauss_test_3_to_4_ver2 = pickle.load(f)\n",
    "\n",
    "#　正解(ラベル)データのロード\n",
    "with open(\"raw_mnist.pkl\",\"rb\") as f:\n",
    "     dataset_raw = pickle.load(f)\n",
    "\n",
    "###　訓練データ\n",
    "#　reshapeと型変換\n",
    "dataset_train_0_real_ver2 = dataset_train_0_real_ver2.astype('float32').reshape(60000,784)\n",
    "dataset_train_1_real_ver2 = dataset_train_1_real_ver2.astype('float32').reshape(60000,784)\n",
    "dataset_train_1_imag_ver2 = dataset_train_1_imag_ver2.astype('float32').reshape(60000,784)\n",
    "dataset_train_2_real_ver2 = dataset_train_2_real_ver2.astype('float32').reshape(60000,784)\n",
    "dataset_train_2_imag_ver2 = dataset_train_2_imag_ver2.astype('float32').reshape(60000,784)\n",
    "dataset_train_3_real_ver2 = dataset_train_3_real_ver2.astype('float32').reshape(60000,784)\n",
    "dataset_train_3_imag_ver2 = dataset_train_3_imag_ver2.astype('float32').reshape(60000,784)\n",
    "dataset_train_4_real_ver2 = dataset_train_4_real_ver2.astype('float32').reshape(60000,784)\n",
    "dataset_train_4_imag_ver2 = dataset_train_4_imag_ver2.astype('float32').reshape(60000,784)\n",
    "\n",
    "#　正規化\n",
    "dataset_train_0 = sp.stats.zscore(dataset_train_0_real_ver2,axis=None)\n",
    "dataset_train_1 = sp.stats.zscore((dataset_train_1_real_ver2**2 + dataset_train_1_imag_ver2**2)**0.5,axis=None)\n",
    "dataset_train_2 = sp.stats.zscore((dataset_train_2_real_ver2**2 + dataset_train_2_imag_ver2**2)**0.5,axis=None)\n",
    "dataset_train_3 = sp.stats.zscore((dataset_train_3_real_ver2**2 + dataset_train_3_imag_ver2**2)**0.5,axis=None)\n",
    "dataset_train_4 = sp.stats.zscore((dataset_train_4_real_ver2**2 + dataset_train_4_imag_ver2**2)**0.5,axis=None)\n",
    "\n",
    "\n",
    "X_train_base = np.stack((dataset_train_0.reshape(60000,28,28), dataset_train_1.reshape(60000,28,28),\n",
    "                         dataset_train_2.reshape(60000,28,28), dataset_train_3.reshape(60000,28,28), \n",
    "                         dataset_train_4.reshape(60000,28,28)),axis=3)\n",
    "\n",
    "###\n",
    "#　テストデータのロード\n",
    "with open(\"second_gauss_test_0_to_2_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_second_gauss_test_0_to_2_ver2 = pickle.load(f)\n",
    "with open(\"second_gauss_test_3_to_4_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_second_gauss_test_3_to_4_ver2 = pickle.load(f)\n",
    "\n",
    "# reshapeと型変換\n",
    "test_0_real = dataset_second_gauss_test_0_to_2_ver2[\"test_0_real\"].astype('float32').reshape(10000,784)\n",
    "test_1_real = dataset_second_gauss_test_0_to_2_ver2[\"test_1_real\"].astype('float32').reshape(10000,784)\n",
    "test_1_imag = dataset_second_gauss_test_0_to_2_ver2[\"test_1_imag\"].astype('float32').reshape(10000,784)\n",
    "test_2_real = dataset_second_gauss_test_0_to_2_ver2[\"test_2_real\"].astype('float32').reshape(10000,784)\n",
    "test_2_imag = dataset_second_gauss_test_0_to_2_ver2[\"test_2_imag\"].astype('float32').reshape(10000,784)\n",
    "test_3_real = dataset_second_gauss_test_3_to_4_ver2[\"test_3_real\"].astype('float32').reshape(10000,784)\n",
    "test_3_imag = dataset_second_gauss_test_3_to_4_ver2[\"test_3_imag\"].astype('float32').reshape(10000,784)\n",
    "test_4_real = dataset_second_gauss_test_3_to_4_ver2[\"test_4_real\"].astype('float32').reshape(10000,784)\n",
    "test_4_imag = dataset_second_gauss_test_3_to_4_ver2[\"test_4_imag\"].astype('float32').reshape(10000,784)\n",
    "# 行ごとの正規化\n",
    "dataset_test_0 = sp.stats.zscore(test_0_real,axis=None)\n",
    "dataset_test_1 = sp.stats.zscore((test_1_real**2 + test_1_imag**2)**0.5,axis=None)\n",
    "dataset_test_2 = sp.stats.zscore((test_2_real**2 + test_2_imag**2)**0.5,axis=None)\n",
    "dataset_test_3 = sp.stats.zscore((test_3_real**2 + test_3_imag**2)**0.5,axis=None)\n",
    "dataset_test_4 = sp.stats.zscore((test_4_real**2 + test_4_imag**2)**0.5,axis=None)\n",
    "X_test = np.stack((dataset_test_0.reshape(10000,28,28), dataset_test_1.reshape(10000,28,28), dataset_test_2.reshape(10000,28,28), \n",
    "                   dataset_test_3.reshape(10000,28,28), dataset_test_4.reshape(10000,28,28)),axis=3)\n",
    "\n",
    "#　正解(ラベル)データのロード\n",
    "with open(\"raw_mnist.pkl\",\"rb\") as f:\n",
    "     dataset_raw = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "4b2b4374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (48000, 28, 28, 9)\n",
      "X_validation: (12000, 28, 28, 9)\n",
      "X_test: (10000, 28, 28, 9)\n",
      "y_train: (48000, 10)\n",
      "y_validation: (12000, 10)\n",
      "y_test: (10000, 10)\n",
      "Epoch 1/20\n",
      "480/480 [==============================] - 37s 76ms/step - loss: 0.1841 - categorical_crossentropy: 0.1841 - accuracy: 0.9485 - val_loss: 0.0789 - val_categorical_crossentropy: 0.0789 - val_accuracy: 0.9758\n",
      "Epoch 2/20\n",
      "480/480 [==============================] - 34s 71ms/step - loss: 0.0920 - categorical_crossentropy: 0.0920 - accuracy: 0.9736 - val_loss: 0.0724 - val_categorical_crossentropy: 0.0724 - val_accuracy: 0.9807\n",
      "Epoch 3/20\n",
      "424/480 [=========================>....] - ETA: 3s - loss: 0.0794 - categorical_crossentropy: 0.0794 - accuracy: 0.9780"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1599196/770924758.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# Early stoppingを適用してフィッティング\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m log2 = model.fit(X_train, y_train, batch_size=100 ,epochs=20, verbose=True,\n\u001b[0m\u001b[1;32m     54\u001b[0m                 \u001b[0;31m#callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                   \u001b[0;31m#                                   min_delta=0, patience=10,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1562\u001b[0m                         ):\n\u001b[1;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1564\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1565\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2494\u001b[0m       (graph_function,\n\u001b[1;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2497\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1860\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1861\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1862\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1863\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "# MNIST 複数チャンネル用\n",
    "# Kerasに付属の手書き数字画像データをダウンロード\n",
    "labels_train_base = dataset_raw[\"y_train\"]\n",
    "labels_test = dataset_raw[\"y_test\"]\n",
    "#X_train_base = X_train.transpose(0,2,3,1)\n",
    "\n",
    "# Training set を学習データ（X_train, labels_train）と検証データ（X_validation, labels_validation）に8:2で分割する\n",
    "X_train,X_validation,labels_train,labels_validation = train_test_split(X_train_base,labels_train_base,test_size = 0.2) \n",
    "# 各画像は行列なので1次元に変換→X_train,X_validation,X_testを上書き\n",
    "\n",
    "#X_test = X_test.transpose(3,1,2,0)\n",
    "y_train = to_categorical(labels_train)\n",
    "y_validation = to_categorical(labels_validation)\n",
    "y_test = to_categorical(labels_test)    \n",
    "\n",
    "print(\"X_train:\",X_train.shape)\n",
    "print(\"X_validation:\",X_validation.shape)\n",
    "print(\"X_test:\",X_test.shape)\n",
    "print(\"y_train:\",y_train.shape)\n",
    "print(\"y_validation:\",y_validation.shape)\n",
    "print(\"y_test:\",y_test.shape)\n",
    "\n",
    "y_train = to_categorical(labels_train)\n",
    "y_validation = to_categorical(labels_validation)\n",
    "y_test = to_categorical(labels_test)\n",
    "\n",
    "bias_init = 0.1\n",
    "\n",
    "# 学習率\n",
    "rate       = 0.005\n",
    "\n",
    "# Sequentialクラスを使ってモデルを準備する\n",
    "model = Sequential()\n",
    "\n",
    "# 隠れ層を追加\n",
    "#model.add(Dense(32,kernel_regularizer=keras.regularizers.l2(rate),input_shape=(28, 28, 9)))\n",
    "#model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(32,kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 9)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "\n",
    "# 出力層を追加\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# TensorFlowのモデルを構築\n",
    "model.compile(optimizer=tf.optimizers.Adam(rate),\n",
    "              loss='categorical_crossentropy', metrics=['categorical_crossentropy', 'accuracy'])\n",
    "\n",
    "# Early stoppingを適用してフィッティング\n",
    "log2 = model.fit(X_train, y_train, batch_size=100 ,epochs=20, verbose=True,\n",
    "                #callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                  #                                   min_delta=0, patience=10, \n",
    "                    #                                     verbose=1)],\n",
    "                validation_data=(X_validation, y_validation))\n",
    "\n",
    "#model.save(HOME+\"/研究/MNIST/second_MNIST/models/second_mnist_abs_model\")\n",
    "\n",
    "# Test dataで予測を実行。\n",
    "pred_test = np.argmax(model.predict(X_test), axis=-1)\n",
    "\n",
    "validation = (pred_test == labels_test)\n",
    "size       = validation.size\n",
    "size\n",
    "correct    = np.count_nonzero(validation)\n",
    "print(f\"{correct}/{size} correct ({correct*100/size:.3f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0941666",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(log2.history).to_csv(HOME+\"/研究/MNIST/second_MNIST/second_mnist_log.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3ba72ee",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mse</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.144794</td>\n",
       "      <td>0.006325</td>\n",
       "      <td>0.957542</td>\n",
       "      <td>0.074043</td>\n",
       "      <td>0.003142</td>\n",
       "      <td>0.979750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.055256</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>0.984875</td>\n",
       "      <td>0.062944</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.981000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.036789</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>0.990104</td>\n",
       "      <td>0.066210</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>0.981750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028665</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.992583</td>\n",
       "      <td>0.059893</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.983917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022400</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.994646</td>\n",
       "      <td>0.056970</td>\n",
       "      <td>0.002332</td>\n",
       "      <td>0.984750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.018792</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.996042</td>\n",
       "      <td>0.057450</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>0.985417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.014657</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.996979</td>\n",
       "      <td>0.063358</td>\n",
       "      <td>0.002313</td>\n",
       "      <td>0.985500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.013249</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.997312</td>\n",
       "      <td>0.062051</td>\n",
       "      <td>0.002241</td>\n",
       "      <td>0.985833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.015703</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.996229</td>\n",
       "      <td>0.065835</td>\n",
       "      <td>0.002458</td>\n",
       "      <td>0.984167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.013498</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.997187</td>\n",
       "      <td>0.068895</td>\n",
       "      <td>0.002531</td>\n",
       "      <td>0.984417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.010108</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.998062</td>\n",
       "      <td>0.075179</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>0.984583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.010565</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.997750</td>\n",
       "      <td>0.066118</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.985083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.009095</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.998146</td>\n",
       "      <td>0.072394</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.984917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.010136</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.997771</td>\n",
       "      <td>0.071810</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.984917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.009132</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.998167</td>\n",
       "      <td>0.070589</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>0.985000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.998729</td>\n",
       "      <td>0.075323</td>\n",
       "      <td>0.002478</td>\n",
       "      <td>0.985333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.006883</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.998792</td>\n",
       "      <td>0.068395</td>\n",
       "      <td>0.002256</td>\n",
       "      <td>0.986417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.006883</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.998771</td>\n",
       "      <td>0.068137</td>\n",
       "      <td>0.002330</td>\n",
       "      <td>0.985333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.007397</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.998542</td>\n",
       "      <td>0.067286</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>0.986250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.006481</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.998812</td>\n",
       "      <td>0.074901</td>\n",
       "      <td>0.002218</td>\n",
       "      <td>0.987000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss       mse  accuracy  val_loss   val_mse  val_accuracy\n",
       "0   0.144794  0.006325  0.957542  0.074043  0.003142      0.979750\n",
       "1   0.055256  0.002327  0.984875  0.062944  0.002770      0.981000\n",
       "2   0.036789  0.001504  0.990104  0.066210  0.002828      0.981750\n",
       "3   0.028665  0.001153  0.992583  0.059893  0.002462      0.983917\n",
       "4   0.022400  0.000837  0.994646  0.056970  0.002332      0.984750\n",
       "5   0.018792  0.000657  0.996042  0.057450  0.002295      0.985417\n",
       "6   0.014657  0.000466  0.996979  0.063358  0.002313      0.985500\n",
       "7   0.013249  0.000429  0.997312  0.062051  0.002241      0.985833\n",
       "8   0.015703  0.000585  0.996229  0.065835  0.002458      0.984167\n",
       "9   0.013498  0.000451  0.997187  0.068895  0.002531      0.984417\n",
       "10  0.010108  0.000307  0.998062  0.075179  0.002593      0.984583\n",
       "11  0.010565  0.000347  0.997750  0.066118  0.002439      0.985083\n",
       "12  0.009095  0.000276  0.998146  0.072394  0.002483      0.984917\n",
       "13  0.010136  0.000353  0.997771  0.071810  0.002443      0.984917\n",
       "14  0.009132  0.000290  0.998167  0.070589  0.002534      0.985000\n",
       "15  0.007407  0.000214  0.998729  0.075323  0.002478      0.985333\n",
       "16  0.006883  0.000194  0.998792  0.068395  0.002256      0.986417\n",
       "17  0.006883  0.000200  0.998771  0.068137  0.002330      0.985333\n",
       "18  0.007397  0.000236  0.998542  0.067286  0.002283      0.986250\n",
       "19  0.006481  0.000190  0.998812  0.074901  0.002218      0.987000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.read_csv(HOME+\"/研究/MNIST/second_MNIST/second_mnist_log.csv\")\n",
    "a\n",
    "# second_mnist_9layer: 9875/10000 correct (98.750%)\n",
    "# second_mnist_5layer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "67675be5",
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [28, 60000]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1094240/1798495821.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Training set を学習データ（X_train, labels_train）と検証データ（X_validation, labels_validation）に8:2で分割する\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_base\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_train_base\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;31m# 各画像は行列なので1次元に変換→X_train,X_validation,X_testを上書き\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m48000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2415\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2417\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [28, 60000]"
     ]
    }
   ],
   "source": [
    "#MNIST複数チャンネル用(Flatニューラルネットワーク)\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "# MNIST 複数チャンネル用\n",
    "# Kerasに付属の手書き数字画像データをダウンロード\n",
    "labels_train_base = dataset_raw[\"y_train\"]\n",
    "\n",
    "#X_train_base = dataset_train_0_to_2[\"second_gauss_train_0_to_2\"][2]\n",
    "#X_train_base = np.vstack((dataset_train_0_to_2[\"second_gauss_train_0_to_2\"],dataset_train_3_to_4[\"second_gauss_train_3_to_4\"]))\n",
    "#X_train_base = X_train_base.transpose(1,0,2)\n",
    "\n",
    "\n",
    "#X_test = dataset_test[\"second_gauss_test\"]\n",
    "#X_test = X_test.reshape(9,10000,784)\n",
    "#X_test = X_test.transpose(1,0,2)\n",
    "labels_test = dataset_raw[\"y_test\"]\n",
    "X_train_base = X_train\n",
    "# 軸を交換\n",
    "#X_train_base = X_train_base.transpose(1,0,2)\n",
    "#labels_test_9 = labels_test\n",
    "#labels_train_9 = labels_train_base\n",
    "\n",
    "X_train_base = X_train.transpose(1,2,3,0)\n",
    "\n",
    "# Training set を学習データ（X_train, labels_train）と検証データ（X_validation, labels_validation）に8:2で分割する\n",
    "X_train,X_validation,labels_train,labels_validation = train_test_split(X_train_base,labels_train_base,test_size = 0.2) \n",
    "# 各画像は行列なので1次元に変換→X_train,X_validation,X_testを上書き\n",
    "X_train = X_train.reshape(9,48000,784)\n",
    "X_validation = X_validation.reshape(9,12000,784)\n",
    "X_test= X_test.reshape(9,10000,784)\n",
    "#正規化 (行ごとの正規化)\n",
    "X_train = X_train.astype('float32')\n",
    "X_validation = X_validation.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = sp.stats.zscore(X_train,axis=1)\n",
    "X_validation = sp.stats.zscore(X_validation,axis=1)\n",
    "X_test = sp.stats.zscore(X_test,axis=1)\n",
    "X_train = X_train.reshape(48000,28,28,9)\n",
    "X_validation = X_validation.reshape(12000,28,28,9)\n",
    "X_test= X_test.reshape(10000,28,28,9)\n",
    "\n",
    "X_train = X_train.transpose(1,0,2)\n",
    "X_train = [X_train[0].reshape(48000,28,28), X_train[1].reshape(48000,28,28), X_train[2].reshape(48000,28,28), \n",
    "               X_train[3].reshape(48000,28,28), X_train[4].reshape(48000,28,28), X_train[5].reshape(48000,28,28), \n",
    "               X_train[6].reshape(48000,28,28), X_train[7].reshape(48000,28,28), X_train[8].reshape(48000,28,28)]\n",
    "X_train = np.array(X_train)\n",
    "\n",
    "#X_test = X_test.transpose(1,0,2)\n",
    "X_test = [X_test[0].reshape(10000,28,28), X_test[1].reshape(10000,28,28), X_test[2].reshape(10000,28,28), \n",
    "               X_test[3].reshape(10000,28,28), X_test[4].reshape(10000,28,28), X_test[5].reshape(10000,28,28), \n",
    "               X_test[6].reshape(10000,28,28), X_test[7].reshape(10000,28,28), X_test[8].reshape(10000,28,28)]\n",
    "X_test = np.array(X_test)\n",
    "X_test = X_test.transpose(1,2,3,0)\n",
    "\n",
    "X_validation = X_validation.transpose(1,0,2)\n",
    "X_validation = [X_validation[0].reshape(12000,28,28), X_validation[1].reshape(12000,28,28), X_validation[2].reshape(12000,28,28), \n",
    "               X_validation[3].reshape(12000,28,28), X_validation[4].reshape(12000,28,28), X_validation[5].reshape(12000,28,28), \n",
    "               X_validation[6].reshape(12000,28,28), X_validation[7].reshape(12000,28,28), X_validation[8].reshape(12000,28,28)]\n",
    "X_validation = np.array(X_validation)\n",
    "#X_validation = X_validation.transpose(1,2,3,0)\n",
    "\n",
    "#X_train = X_train.transpose(3,1,2,0)\n",
    "# labels_train, labels_validation, labels_test をダミー変数化して y_train, y_validation, y_test に格納する\n",
    "#　さらにreshape\"\"\n",
    "\n",
    "#X_train = X_train.reshape(48000,28,28,9)\n",
    "#X_validation = X_validation.reshape(12000,28,28,9)\n",
    "#X_test = X_test.reshape(10000,28,28,9)\n",
    "y_train = to_categorical(labels_train)\n",
    "y_validation = to_categorical(labels_validation)\n",
    "y_test = to_categorical(labels_test)    \n",
    "\n",
    "print(\"X_train:\",X_train.shape)\n",
    "print(\"X_validation:\",X_validation.shape)\n",
    "print(\"X_test:\",X_test.shape)\n",
    "print(\"y_train:\",y_train.shape)\n",
    "print(\"y_validation:\",y_validation.shape)\n",
    "print(\"y_test:\",y_test.shape)\n",
    "\n",
    "y_train = to_categorical(labels_train)\n",
    "y_validation = to_categorical(labels_validation)\n",
    "y_test = to_categorical(labels_test)\n",
    "\n",
    "#X_train = X_train.reshape(-1,784)\n",
    "#X_validation = X_validation.reshape(-1,784)\n",
    "#X_test = X_test.reshape(-1,784)\n",
    "\n",
    "# パラメータの設定\n",
    "n_features = 784\n",
    "n_hidden   = 100\n",
    "bias_init = 0.1\n",
    "\n",
    "# 学習率\n",
    "rate       = 0.003\n",
    "\n",
    "# Sequentialクラスを使ってモデルを準備する\n",
    "model = Sequential()\n",
    "#model = multi_gpu_model(model, gpus=1)\n",
    "\n",
    "# 隠れ層を追加\n",
    "#model.add(tf.keras.Input(shape=(1,n_features,9)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(n_hidden,activation='relu',input_shape=(1,n_features,9)))\n",
    "model.add(Dense(n_hidden,activation='relu'))\n",
    "model.add(Dense(n_hidden,activation='relu'))\n",
    "\n",
    "# 出力層を追加\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "# 隠れ層を追加\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(28, 28, 9)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "#model.add(Flatten())\n",
    "model.add(Flatten())\n",
    "\n",
    "# 出力層を追加\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# TensorFlowのモデルを構築\n",
    "model.compile(optimizer=tf.optimizers.Adam(rate),\n",
    "              loss='categorical_crossentropy', metrics=['mae', 'accuracy'])\n",
    "\n",
    "# Early stoppingを適用してフィッティング\n",
    "log = model.fit(X_train, y_train, batch_size=200 ,epochs=1, verbose=True,\n",
    "                callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                     min_delta=0, patience=10, \n",
    "                                                         verbose=1)],\n",
    "                validation_data=(X_validation, y_validation))\n",
    "\n",
    "# Test dataで予測を実行。\n",
    "#pred_test = model.predict_classes(X_test)\n",
    "pred_test = np.argmax(model.predict(X_test), axis=-1)\n",
    "\n",
    "validation = (pred_test == labels_test)\n",
    "size       = validation.size\n",
    "size\n",
    "correct    = np.count_nonzero(validation)\n",
    "print(f\"{correct}/{size} correct ({correct*100/size:.3f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60b8458",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "(MNIST保存)[https://circleken.net/2020/08/post19/]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53693cb9",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "(ガウシアンフィルタでぼかす)[ https://algorithm.joho.info/programming/python/opencv-gaussian-filter-py/ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3250d197",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "with open(\"MNIST_pickle/raw_mnist.pkl\",\"rb\") as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d21feb90",
   "metadata": {
    "code_folding": [
     0,
     2,
     18,
     35
    ],
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    # output\\n    # 結果を出力\\n    list1[i] = dst.reshape(-1,784)[0]\\n\\nlist1 = np.array(list1)\\nfirst_gauss_dic[\"first_gauss_train\"] = list1\\n\\n#\\u3000テストデータ\\nfor i in range(img_test.shape[0]):\\n    \\n    # convert grayscale\\n    # グレースケール変換\\n    #gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\\n\\n    # Spatial filtering\\n    dst = cv2.GaussianBlur(img_test[i].reshape(28,28), ksize=(3, 3), sigmaX=0.5)\\n\\n    # output\\n    # 結果を出力\\n    list2[i] = dst.reshape(-1,784)[0]\\n\\nlist2 = np.array(list2)\\nfirst_gauss_dic[\"first_gauss_test\"] = list2\\n\\nsave_file = \\'first_gauss_images.pkl\\'\\nf = open(save_file,\"wb\")\\n\\nwith open(save_file, \\'wb\\') as f:\\n    pickle.dump(first_gauss_dic,f, -1)'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ガウシアンでぼかす\n",
    "\"\"\"\n",
    "with open(\"raw_mnist.pkl\",\"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "import cv2\n",
    "\n",
    "# load image (grayscale)\n",
    "# 入力画像を読み込み\n",
    "img_train = dataset[\"X_train\"]\n",
    "img_test = dataset[\"X_test\"]\n",
    "\n",
    "#　ぼかした後の画像をまとめるnumpy配列\n",
    "#　訓練データ\n",
    "#dataset[\"X_train_val_first_gauss\"] = np.array([])\n",
    "first_gauss_dic = {}\n",
    "list1 = [[]]*60000\n",
    "list2 = [[]]*10000\n",
    "for i in range(img_train.shape[0]):\n",
    "    \n",
    "    # convert grayscale\n",
    "    # グレースケール変換\n",
    "    #gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Spatial filtering\n",
    "    dst = cv2.GaussianBlur(img_train[i].reshape(28,28), ksize=(3, 3), sigmaX=0.5)\n",
    "\n",
    "    # output\n",
    "    # 結果を出力\n",
    "    list1[i] = dst.reshape(-1,784)[0]\n",
    "\n",
    "list1 = np.array(list1)\n",
    "first_gauss_dic[\"first_gauss_train\"] = list1\n",
    "\n",
    "#　テストデータ\n",
    "for i in range(img_test.shape[0]):\n",
    "    \n",
    "    # convert grayscale\n",
    "    # グレースケール変換\n",
    "    #gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Spatial filtering\n",
    "    dst = cv2.GaussianBlur(img_test[i].reshape(28,28), ksize=(3, 3), sigmaX=0.5)\n",
    "\n",
    "    # output\n",
    "    # 結果を出力\n",
    "    list2[i] = dst.reshape(-1,784)[0]\n",
    "\n",
    "list2 = np.array(list2)\n",
    "first_gauss_dic[\"first_gauss_test\"] = list2\n",
    "\n",
    "save_file = 'first_gauss_images.pkl'\n",
    "f = open(save_file,\"wb\")\n",
    "\n",
    "with open(save_file, 'wb') as f:\n",
    "    pickle.dump(first_gauss_dic,f, -1)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786a3f3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "--- \n",
    "(画像を微分)[ https://algorithm.joho.info/programming/python/opencv-differential-filter-py/ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd9ec161-1bc4-4753-b2a0-8b1fc4c9cc75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yy/y.shinozaki/研究/MNIST/MNIST_pickle\n"
     ]
    }
   ],
   "source": [
    "cd MNIST_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "225e085e",
   "metadata": {
    "code_folding": [
     26,
     62
    ],
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0まで終了\n",
      "2022/11/05 06:51:32\n",
      "5000まで終了\n",
      "2022/11/05 06:51:32\n",
      "10000まで終了\n",
      "2022/11/05 06:51:32\n",
      "15000まで終了\n",
      "2022/11/05 06:51:32\n",
      "20000まで終了\n",
      "2022/11/05 06:51:32\n",
      "25000まで終了\n",
      "2022/11/05 06:51:32\n",
      "30000まで終了\n",
      "2022/11/05 06:51:33\n",
      "35000まで終了\n",
      "2022/11/05 06:51:33\n",
      "40000まで終了\n",
      "2022/11/05 06:51:33\n",
      "45000まで終了\n",
      "2022/11/05 06:51:33\n",
      "50000まで終了\n",
      "2022/11/05 06:51:33\n",
      "55000まで終了\n",
      "2022/11/05 06:51:33\n",
      "0まで終了\n",
      "2022/11/05 06:51:33\n",
      "5000まで終了\n",
      "2022/11/05 06:51:33\n"
     ]
    }
   ],
   "source": [
    "# 画像を微分する\n",
    "\n",
    "\"\"\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "list1 = [[]]*60000\n",
    "list2 = [[]]*60000\n",
    "list3 = [[]]*60000\n",
    "\n",
    "\n",
    "# カーネル（水平、垂直方向の輪郭検出用）\n",
    "kernel_x = np.array([[0, -1, 0],\n",
    "                         [0, 0, 0],\n",
    "                         [0, 1, 0]])\n",
    "\n",
    "kernel_y = np.array([[0, 0, 0],\n",
    "                        [-1, 0, 1],\n",
    "                        [0, 0, 0]])\n",
    "\n",
    "with open(\"first_gauss_images.pkl\",\"rb\") as f:\n",
    "    dataset_first_gauss = pickle.load(f)\n",
    "\n",
    "#　訓練画像を微分\n",
    "for i in range(60000):\n",
    "    if i%5000==0:\n",
    "        print(\"{}まで終了\".format(i))\n",
    "        now = time.strftime('%Y/%m/%d %H:%M:%S')\n",
    "        print(now)\n",
    "    # 入力画像を読み込み\n",
    "    #img = cv2.imread(osp.join(HOME, \"研究/MNIST/Training_Images/First_Gaussian_Images/{}.png\".format(str(i).zfill(5))))\n",
    "    img = dataset_first_gauss[\"first_gauss_train\"]\n",
    "    # グレースケール変換\n",
    "    #gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # 方法2\n",
    "    gray_x = cv2.filter2D(img[i].reshape(28,28), cv2.CV_64F, kernel_x)\n",
    "    gray_y = cv2.filter2D(img[i].reshape(28,28), cv2.CV_64F, kernel_y)\n",
    "    #dst = np.sqrt(gray_x ** 2 + gray_y ** 2)\n",
    "    dst = gray_x ** 2 + gray_y ** 2\n",
    "    #dst = np.sqrt(np.dot(gray_x,gray_x)+ np.dot(gray_y, gray_y))\n",
    "    #np.sqrt(np.linalg.norm(gray_x)+np.linalg.norm(gray_y))\n",
    "    # 結果を出力\n",
    "    list1[i] = gray_x.reshape(-1,784)[0]\n",
    "    list2[i] = gray_y.reshape(-1,784)[0]\n",
    "    list3[i] = dst.reshape(-1,784)[0]\n",
    "    \n",
    "list1_2 = np.array(list1)\n",
    "list2_2 = np.array(list2)\n",
    "list3_2 = np.array(list3)\n",
    "    \n",
    "diff_images[\"diff_x_train\"] = list1_2\n",
    "diff_images[\"diff_y_train\"] = list2_2\n",
    "diff_images[\"diff_dist_train\"] = list3_2\n",
    "\n",
    "\n",
    "#　テスト画像を微分\n",
    "list1 = [[]]*10000\n",
    "list2 = [[]]*10000\n",
    "list3 = [[]]*10000\n",
    "\n",
    "for i in range(10000):\n",
    "    if i%5000==0:\n",
    "        print(\"{}まで終了\".format(i))\n",
    "        now = time.strftime('%Y/%m/%d %H:%M:%S')\n",
    "        print(now)\n",
    "    # 入力画像を読み込み\n",
    "    #img = cv2.imread(osp.join(HOME, \"研究/MNIST/Training_Images/First_Gaussian_Images/{}.png\".format(str(i).zfill(5))))\n",
    "    img = dataset_first_gauss[\"first_gauss_test\"]\n",
    "    # グレースケール変換\n",
    "    #gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # 方法2\n",
    "    gray_x = cv2.filter2D(img[i].reshape(28,28), cv2.CV_64F, kernel_x)\n",
    "    gray_y = cv2.filter2D(img[i].reshape(28,28), cv2.CV_64F, kernel_y)\n",
    "    #dst = np.sqrt(gray_x ** 2 + gray_y ** 2)\n",
    "    dst = gray_x ** 2 + gray_y ** 2\n",
    "    #dst = np.dot(gray_x,gray_x)+ np.dot(gray_y, gray_y)\n",
    "    #dst = np.sqrt(np.linalg.norm(gray_x)+np.linalg.norm(gray_y))\n",
    "    # 結果を出力\n",
    "    list1[i] = gray_x.reshape(-1,784)[0]\n",
    "    list2[i] = gray_y.reshape(-1,784)[0]\n",
    "    list3[i] = dst.reshape(-1,784)[0]\n",
    "    \n",
    "list1_2 = np.array(list1)\n",
    "list2_2 = np.array(list2)\n",
    "list3_2 = np.array(list3)\n",
    "    \n",
    "diff_images[\"diff_x_test\"] = list1_2\n",
    "diff_images[\"diff_y_test\"] = list2_2\n",
    "diff_images[\"diff_dist_test\"] = list3_2\n",
    "\n",
    "\n",
    "save_file = 'diff_images.pkl'\n",
    "f = open(save_file,\"wb\")\n",
    "\n",
    "with open(save_file, 'wb') as f:\n",
    "    pickle.dump(diff_images,f, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6192c1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yy/y.shinozaki/研究/MNIST/MNIST_pickle\n"
     ]
    }
   ],
   "source": [
    "cd MNIST_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee577d34-1fbc-45a1-ab48-02f994a08bfe",
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Image'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1121419/3963625350.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1020\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#img_x_diff = dataset_diff[\"diff_x_train\"][i]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#img_y_diff = dataset_diff[\"diff_x_train\"][i]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#img_diff_dist = dataset_diff[\"diff_dist_train\"][i]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Image'"
     ]
    }
   ],
   "source": [
    "for i in range(1000,1020):\n",
    "    #img_x_diff = dataset_diff[\"diff_x_train\"][i]\n",
    "    #img_y_diff = dataset_diff[\"diff_x_train\"][i]\n",
    "    #img_diff_dist = dataset_diff[\"diff_dist_train\"][i]\n",
    "    #img_diff_dist = np.sqrt(img_diff_dist)\n",
    "    #img_x = dataset_diff[\"diff_x_test\"][i]\n",
    "    #img_y = dataset_diff[\"diff_y_test\"][i]\n",
    "    img_dst = dataset_diff[\"diff_dist_train\"][i]\n",
    "    #print(labels_train_base[i])\n",
    "    #Image.fromarray(img_x.reshape(28,28)).show()\n",
    "    #Image.fromarray(img_y.reshape(28,28)).show()\n",
    "    Image.fromarray(img_dst.reshape(28,28)).show()\n",
    "    #Image.fromarray(img_x_diff.reshape(28,28)).show()\n",
    "    #Image.fromarray(img_y_diff.reshape(28,28)).show()\n",
    "    #Image.fromarray(img_diff_dist.reshape(28,28)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07479723",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "画像のフーリエ記述子を求める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae4e5eaa",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#画像のフーリエ記述子を求める\n",
    "\n",
    "import pickle\n",
    "from math import pi\n",
    "\n",
    "# epsilon\n",
    "ep = 10 ** -12\n",
    "\n",
    "# Q = 4とする\n",
    "Q = 4\n",
    "#list_name = [\"train_four_coeff_0\",\"train_four_coeff_1\",\"train_four_coeff_2\",\"train_four_coeff_3\",\"train_four_coeff_4\"]\n",
    "list_name = [{},{},{},{},{}]\n",
    "with open(\"diff_images.pkl\",\"rb\") as f:\n",
    "    dataset_diff = pickle.load(f)\n",
    "diff_x_train = dataset_diff[\"diff_x_train\"]\n",
    "diff_y_train = dataset_diff[\"diff_y_train\"]\n",
    "diff_x_test = dataset_diff[\"diff_x_test\"]\n",
    "diff_y_test = dataset_diff[\"diff_y_test\"]\n",
    "diff_train_image = diff_x_train - diff_y_train*1j\n",
    "diff_test_image = diff_x_test - diff_y_test*1j\n",
    "sqrt_train = (dataset_diff[\"diff_dist_train\"]+ep) ** 0.5\n",
    "sqrt_test = (dataset_diff[\"diff_dist_test\"]+ep) ** 0.5\n",
    "train_four_coeff_0 = {}\n",
    "train_four_coeff_1 = {}\n",
    "train_four_coeff_2 = {}\n",
    "train_four_coeff_3 = {}\n",
    "train_four_coeff_4 = {}\n",
    "test_four_coeff = {}\n",
    "\n",
    "#　フーリエ記述子導出\n",
    "for i in range(Q+1):\n",
    "    dq_train = sqrt_train/(2*pi) * (diff_train_image/sqrt_train) ** i\n",
    "    dq_test = sqrt_test/(2*pi) * (diff_test_image/sqrt_test) ** i\n",
    "    train_four_coeff_real = dq_train.real\n",
    "    train_four_coeff_imag = dq_train.imag\n",
    "    test_four_coeff_real = dq_test.real\n",
    "    test_four_coeff_imag = dq_test.imag\n",
    "    if i==0:\n",
    "        list_name[i][\"train_four_coeff_layer_{}_real\".format(i)] = train_four_coeff_real\n",
    "        test_four_coeff[\"test_coeff_layer_{}_real\".format(i)] =  test_four_coeff_real\n",
    "    else:\n",
    "        list_name[i][\"train_four_coeff_layer_{}_real\".format(i)] = train_four_coeff_real\n",
    "        list_name[i][\"train_four_coeff_layer_{}_imag\".format(i)] = train_four_coeff_imag\n",
    "        test_four_coeff[\"test_coeff_layer_{}_real\".format(i)] =  test_four_coeff_real\n",
    "        test_four_coeff[\"test_coeff_layer_{}_imag\".format(i)] =  test_four_coeff_imag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84bc4ba3",
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['test_coeff_layer_0_real', 'test_coeff_layer_1_real', 'test_coeff_layer_1_imag', 'test_coeff_layer_2_real', 'test_coeff_layer_2_imag', 'test_coeff_layer_3_real', 'test_coeff_layer_3_imag', 'test_coeff_layer_4_real', 'test_coeff_layer_4_imag'])\n",
      "(10000, 784)\n",
      "(10000, 784)\n",
      "(10000, 784)\n",
      "(10000, 784)\n",
      "(10000, 784)\n",
      "(10000, 784)\n",
      "(10000, 784)\n",
      "(10000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "#　画像のshape確認\n",
    "print(test_four_coeff.keys())\n",
    "print(test_four_coeff[\"test_coeff_layer_0_real\"].shape)\n",
    "print(test_four_coeff[\"test_coeff_layer_1_real\"].shape)\n",
    "print(test_four_coeff[\"test_coeff_layer_1_imag\"].shape)\n",
    "print(test_four_coeff[\"test_coeff_layer_2_real\"].shape)\n",
    "print(test_four_coeff[\"test_coeff_layer_2_imag\"].shape)\n",
    "print(test_four_coeff[\"test_coeff_layer_3_real\"].shape)\n",
    "print(test_four_coeff[\"test_coeff_layer_3_imag\"].shape)\n",
    "print(test_four_coeff[\"test_coeff_layer_4_real\"].shape)\n",
    "print(test_four_coeff[\"test_coeff_layer_4_imag\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f00b99f1",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#　test保存\n",
    "\"\"\"\n",
    "save_file_test_1 = 'test_four_coeff_layer_0_to_2_ver2.pkl'\n",
    "save_file_test_2 = 'test_four_coeff_layer_3_to_4_ver2.pkl'\n",
    "\n",
    "with open(save_file_test_1, 'wb') as f:\n",
    "    test_layer_0_to_2 = {}\n",
    "    test_layer_0_to_2[\"test_coeff_layer_0_real\"] = test_four_coeff[\"test_coeff_layer_0_real\"]\n",
    "    test_layer_0_to_2[\"test_coeff_layer_1_real\"] = test_four_coeff[\"test_coeff_layer_1_real\"]\n",
    "    test_layer_0_to_2[\"test_coeff_layer_1_imag\"] = test_four_coeff[\"test_coeff_layer_1_imag\"]\n",
    "    test_layer_0_to_2[\"test_coeff_layer_2_real\"] = test_four_coeff[\"test_coeff_layer_2_real\"]\n",
    "    test_layer_0_to_2[\"test_coeff_layer_2_imag\"] = test_four_coeff[\"test_coeff_layer_2_imag\"]\n",
    "    pickle.dump(test_layer_0_to_2,f, -1)\n",
    "\n",
    "del test_layer_0_to_2\n",
    "\n",
    "with open(save_file_test_2, 'wb') as f:\n",
    "    test_layer_3_to_4 = {}\n",
    "    test_layer_3_to_4[\"test_coeff_layer_3_real\"] = test_four_coeff[\"test_coeff_layer_3_real\"]\n",
    "    test_layer_3_to_4[\"test_coeff_layer_3_imag\"] = test_four_coeff[\"test_coeff_layer_3_imag\"]\n",
    "    test_layer_3_to_4[\"test_coeff_layer_4_real\"] = test_four_coeff[\"test_coeff_layer_4_real\"]\n",
    "    test_layer_3_to_4[\"test_coeff_layer_4_imag\"] = test_four_coeff[\"test_coeff_layer_4_imag\"]\n",
    "    pickle.dump(test_layer_3_to_4,f, -1)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c6151d0",
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 5] Input/output error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1028151/3638520961.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_four_coeff_0_to_2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error"
     ]
    }
   ],
   "source": [
    "#　フーリエ記述子を保存\n",
    "del train_four_coeff_3_to_4\n",
    "del test_four_coeff\n",
    "\n",
    "save_file = 'train_four_coeff_layer_0_to_2_ver2.pkl'\n",
    "\n",
    "with open(save_file, 'wb') as f:\n",
    "    pickle.dump(train_four_coeff_0_to_2,f, -1)\n",
    "\n",
    "    \n",
    "\"\"\"save_file = 'diff_images.pkl'\n",
    "f = open(save_file,\"wb\")\n",
    "\n",
    "with open(save_file, 'wb') as f:\n",
    "    pickle.dump(diff_images,f, -1) \"\"\"   \n",
    "    \n",
    "\n",
    "\"\"\"save_file_2 = ('second_MNIST/train_four_coeff_layer_3_to_4_ver2.pkl')\n",
    "with open(save_file_2, 'wb') as f:\n",
    "    pickle.dump(train_four_coeff_3_to_4,f, -1)\n",
    "    \n",
    "save_file_3 = ('second_MNIST/test_four_coeff_layer_ver2.pkl')\n",
    "with open(save_file_3, 'wb') as f:\n",
    "    pickle.dump(test_four_coeff,f, -1)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "585dcb30",
   "metadata": {
    "code_folding": [
     18,
     20,
     59
    ],
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1まで終了\n",
      "2022/11/05 14:22:21\n",
      "2まで終了\n",
      "2022/11/05 15:03:10\n",
      "3まで終了\n",
      "2022/11/05 15:43:53\n",
      "4まで終了\n",
      "2022/11/05 16:24:57\n",
      "5まで終了\n",
      "2022/11/05 17:05:48\n",
      "6まで終了\n",
      "2022/11/05 17:46:29\n",
      "7まで終了\n",
      "2022/11/05 18:27:31\n",
      "8まで終了\n",
      "2022/11/05 19:08:34\n",
      "0まで終了\n",
      "2022/11/05 19:09:24\n",
      "1まで終了\n",
      "2022/11/05 19:10:36\n",
      "2まで終了\n",
      "2022/11/05 19:11:52\n",
      "3まで終了\n",
      "2022/11/05 19:13:06\n",
      "4まで終了\n",
      "2022/11/05 19:14:22\n",
      "5まで終了\n",
      "2022/11/05 19:15:38\n",
      "6まで終了\n",
      "2022/11/05 19:16:55\n",
      "7まで終了\n",
      "2022/11/05 19:18:11\n",
      "8まで終了\n",
      "2022/11/05 19:19:27\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# epsilon\n",
    "e = 10 ** -12\n",
    "\n",
    "# Q = 4とする\n",
    "Q = 4\n",
    "\n",
    "import time\n",
    "#four_coeff = {}\n",
    "#four_list = [[]]\n",
    "#four_list = [[]]*784\n",
    "#four_list = [four_list]*9\n",
    "\n",
    "with open(\"diff_images.pkl\",\"rb\") as f:\n",
    "    dataset_diff = pickle.load(f)\n",
    "\n",
    "\n",
    "#　訓練データ\n",
    "for i in range(1,2*Q+1):\n",
    "    four_coeff = {}\n",
    "    for j in range(60000):\n",
    "        diff_x = dataset_diff[\"diff_x_train\"][j].reshape(28,28)\n",
    "        diff_y = dataset_diff[\"diff_y_train\"][j].reshape(28,28)\n",
    "        sqrt = dataset_diff[\"diff_dist_train\"][j].reshape(28,28)\n",
    "        #kari_sqrt =  np.sqrt(sqrt[i]**2+e)\n",
    "        #kari_sqrt =  np.sqrt(np.linalg.matrix_power(sqrt,2)+e)\n",
    "        kari_sqrt =  np.sqrt(sqrt+e)\n",
    "        dq_1 = kari_sqrt/(2*pi)\n",
    "        #dq_2 = (diff_x - diff_y)/kari_sqrt\n",
    "        imag_diff_y = diff_y*1j\n",
    "        dq_2 = diff_x - imag_diff_y\n",
    "        #メモリ解放\n",
    "        #del diff_x, diff_y, sqrt, kari_sqrt\n",
    "\n",
    "        #dq = dq_1 * np.linalg.matrix_power(dq_2,j-1)\n",
    "        if i==0:\n",
    "            dq = dq_1\n",
    "        elif i==1:\n",
    "            dq = (dq_2)/(2*pi)\n",
    "        else:\n",
    "            dq = np.linalg.matrix_power(dq_2,i)/(np.linalg.matrix_power(kari_sqrt,i-1)*2*pi)\n",
    "        if j==0:\n",
    "            kari_array = np.array([dq.reshape(-1,784)[0]])\n",
    "        else:\n",
    "            kari_array = np.vstack((kari_array, dq.reshape(-1,784)[0]))\n",
    "    \n",
    "    four_coeff[\"train_four_coeff_layer{}\".format(str(i))] = kari_array\n",
    "    \n",
    "    print(\"{}まで終了\".format(i))\n",
    "    now = time.strftime('%Y/%m/%d %H:%M:%S')\n",
    "    print(now)\n",
    "    \n",
    "    save_file = ('train_four_coeff_layer{}.pkl'.format(str(i)))\n",
    "    with open(save_file, 'wb') as f:\n",
    "        pickle.dump(four_coeff,f, -1)\n",
    "\n",
    "\n",
    "\n",
    "# テストデータ\n",
    "for i in range(0,2*Q+1):\n",
    "    four_coeff = {}\n",
    "    for j in range(10000):\n",
    "        diff_x = dataset_diff[\"diff_x_test\"][j].reshape(28,28)\n",
    "        diff_y = dataset_diff[\"diff_y_test\"][j].reshape(28,28)\n",
    "        sqrt = dataset_diff[\"diff_dist_test\"][j].reshape(28,28)\n",
    "        #kari_sqrt =  np.sqrt(sqrt[i]**2+e)\n",
    "        kari_sqrt = np.sqrt(sqrt+e)\n",
    "        dq_1 = kari_sqrt/(2*pi)\n",
    "        #dq_2 = (diff_x - diff_y)/kari_sqrt\n",
    "        imag_diff_y = diff_y*1j\n",
    "        dq_2 = diff_x - imag_diff_y\n",
    "        \n",
    "        #メモリ解放\n",
    "        #del diff_x, diff_y, sqrt, kari_sqrt\n",
    "\n",
    "        #dq = dq_1 * np.linalg.matrix_power(dq_2,j-1)\n",
    "        #dq = dq_1 * (dq_2**(i-1))\n",
    "        if i==0:\n",
    "            dq = dq_1\n",
    "        elif i==1:\n",
    "            dq = (dq_2)/(2*pi)\n",
    "        else:\n",
    "            dq = np.linalg.matrix_power(dq_2,i)/(np.linalg.matrix_power(kari_sqrt,i-1)*2*pi)\n",
    "        if j==0:\n",
    "            kari_array = np.array([dq.reshape(-1,784)[0]])\n",
    "        else:\n",
    "            kari_array = np.vstack((kari_array, dq.reshape(-1,784)[0]))\n",
    "    \n",
    "    four_coeff[\"test_four_coeff_layer{}\".format(str(i))] = kari_array\n",
    "    \n",
    "    print(\"{}まで終了\".format(i))\n",
    "    now = time.strftime('%Y/%m/%d %H:%M:%S')\n",
    "    print(now)\n",
    "    \n",
    "    save_file = ('test_four_coeff_layer{}.pkl'.format(str(i)))\n",
    "    with open(save_file, 'wb') as f:\n",
    "        pickle.dump(four_coeff,f, -1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdded4db",
   "metadata": {},
   "source": [
    "---\n",
    "2回目のガウスぼかし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2895de7-c505-42fe-938a-ec179714c3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yy/y.shinozaki/研究/MNIST/MNIST_pickle/second_MNIST\n"
     ]
    }
   ],
   "source": [
    "cd MNIST_pickle/second_MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e7d1490-bc05-4f69-9d4a-33bb10a1e174",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#　データの前処理\n",
    "import pickle\n",
    "#　訓練データ\n",
    "with open(\"train_four_coeff_layer0_real_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_0_real = pickle.load(f)\n",
    "with open(\"train_four_coeff_layer1_real_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_1_real = pickle.load(f)\n",
    "with open(\"train_four_coeff_layer1_imag_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_1_imag = pickle.load(f)\n",
    "with open(\"train_four_coeff_layer2_real_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_2_real = pickle.load(f)\n",
    "with open(\"train_four_coeff_layer2_imag_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_2_imag = pickle.load(f)\n",
    "with open(\"train_four_coeff_layer3_real_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_3_real = pickle.load(f)\n",
    "with open(\"train_four_coeff_layer3_imag_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_3_imag = pickle.load(f)\n",
    "with open(\"train_four_coeff_layer4_real_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_4_real = pickle.load(f)\n",
    "with open(\"train_four_coeff_layer4_imag_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_train_4_imag = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "effa9fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#　テストデータの前処理\n",
    "with open(\"test_four_coeff_layer_0_to_2_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_test_0_to_2 = pickle.load(f)\n",
    "with open(\"test_four_coeff_layer_3_to_4_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_test_3_to_4 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e1cc295f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['test_coeff_layer_3_real', 'test_coeff_layer_3_imag', 'test_coeff_layer_4_real', 'test_coeff_layer_4_imag'])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test_3_to_4.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ac58be2-8cfb-4672-babd-2a61c026b9a5",
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#\\u3000辞書型にする\\ntrain_layer = {}\\ntrain_layer[\"train_0_real\"] = dataset_train_0_real[\"train_four_coeff_layer_0_real\"]\\ntrain_layer[\"train_1_real\"] = dataset_train_1_real[\"train_four_coeff_layer_1_real\"]\\ntrain_layer[\"train_1_imag\"] = dataset_train_1_imag[\"train_four_coeff_layer_1_imag\"]\\ntrain_layer[\"train_2_real\"] = dataset_train_2_real[\"train_four_coeff_layer_2_real\"]\\ntrain_layer[\"train_2_imag\"] = dataset_train_2_imag[\"train_four_coeff_layer_2_imag\"]\\ntrain_layer[\"train_3_real\"] = dataset_train_3_real[\"train_four_coeff_layer_3_real\"]\\ntrain_layer[\"train_3_imag\"] = dataset_train_3_imag[\"train_four_coeff_layer_3_imag\"]\\ntrain_layer[\"train_4_real\"] = dataset_train_4_real[\"train_four_coeff_layer_4_real\"]\\ntrain_layer[\"train_4_imag\"] = dataset_train_4_imag[\"train_four_coeff_layer_4_imag\"]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_train_four_coeff = np.stack((dataset_train_0_real[\"train_four_coeff_layer_0_real\"],dataset_train_1_real[\"train_four_coeff_layer_1_real\"],\n",
    "                        dataset_train_1_imag[\"train_four_coeff_layer_1_imag\"],dataset_train_2_real[\"train_four_coeff_layer_2_real\"],\n",
    "                        dataset_train_2_imag[\"train_four_coeff_layer_2_imag\"],dataset_train_3_real[\"train_four_coeff_layer_3_real\"],\n",
    "                        dataset_train_3_imag[\"train_four_coeff_layer_3_imag\"],dataset_train_4_real[\"train_four_coeff_layer_4_real\"],\n",
    "                        dataset_train_4_imag[\"train_four_coeff_layer_4_imag\"]),axis=0)\n",
    "list_test_four_coeff = np.stack((dataset_test_0_to_2[\"test_coeff_layer_0_real\"],dataset_test_0_to_2[\"test_coeff_layer_1_real\"],\n",
    "                                dataset_test_0_to_2[\"test_coeff_layer_1_imag\"],dataset_test_0_to_2[\"test_coeff_layer_2_real\"],\n",
    "                                dataset_test_0_to_2[\"test_coeff_layer_2_imag\"],dataset_test_3_to_4[\"test_coeff_layer_3_real\"],\n",
    "                                 dataset_test_3_to_4[\"test_coeff_layer_3_imag\"],dataset_test_3_to_4[\"test_coeff_layer_4_real\"],\n",
    "                                 dataset_test_3_to_4[\"test_coeff_layer_4_imag\"]),axis=0)\n",
    "#x_header = np.array(pd.DataFrame(list_train_four_coeff[0]).columns.tolist())\n",
    "#np.savez('mnist_train_four_coeff', x_header, list_train_four_coeff)\n",
    "\"\"\"#　辞書型にする\n",
    "train_layer = {}\n",
    "train_layer[\"train_0_real\"] = dataset_train_0_real[\"train_four_coeff_layer_0_real\"]\n",
    "train_layer[\"train_1_real\"] = dataset_train_1_real[\"train_four_coeff_layer_1_real\"]\n",
    "train_layer[\"train_1_imag\"] = dataset_train_1_imag[\"train_four_coeff_layer_1_imag\"]\n",
    "train_layer[\"train_2_real\"] = dataset_train_2_real[\"train_four_coeff_layer_2_real\"]\n",
    "train_layer[\"train_2_imag\"] = dataset_train_2_imag[\"train_four_coeff_layer_2_imag\"]\n",
    "train_layer[\"train_3_real\"] = dataset_train_3_real[\"train_four_coeff_layer_3_real\"]\n",
    "train_layer[\"train_3_imag\"] = dataset_train_3_imag[\"train_four_coeff_layer_3_imag\"]\n",
    "train_layer[\"train_4_real\"] = dataset_train_4_real[\"train_four_coeff_layer_4_real\"]\n",
    "train_layer[\"train_4_imag\"] = dataset_train_4_imag[\"train_four_coeff_layer_4_imag\"]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "4e833504",
   "metadata": {
    "code_folding": [],
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ガウシアンでぼかす\n",
    "import cv2\n",
    "\n",
    "# load image (grayscale)\n",
    "# 入力画像を読み込み\n",
    "#img_train = dataset[\"X_train\"]\n",
    "#img_test = dataset[\"X_test\"]\n",
    "\n",
    "#　ぼかした後の画像をまとめるnumpy配列\n",
    "#　訓練データ\n",
    "#dataset[\"X_train_val_first_gauss\"] = np.array([])\n",
    "#second_gauss_train_0_to_2 = {}\n",
    "#second_gauss_train_3_to_4 = {}\n",
    "\n",
    "Q = 4\n",
    "sigma_value = 1\n",
    "second_gauss_train = np.zeros((9,60000,784))\n",
    "second_gauss_test = np.zeros((9,10000,784))\n",
    "\n",
    "for i in range(2*Q+1):\n",
    "    second_gauss_train[i] = cv2.GaussianBlur(list_train_four_coeff[i], ksize=(3, 3), sigmaX=sigma_value)\n",
    "    second_gauss_test[i] = cv2.GaussianBlur(list_test_four_coeff[i], ksize=(3, 3), sigmaX=sigma_value)\n",
    "    \n",
    "#　いらないかも?\n",
    "    \"\"\"list_train_0_real = cv2.GaussianBlur(train_layer[\"train_0_real\"].reshape(60000,28,28), ksize=(3, 3), sigmaX=sigma_value)\n",
    "    list_train_1_real = cv2.GaussianBlur(train_layer[\"train_1_real\"].reshape(60000,28,28), ksize=(3, 3), sigmaX=sigma_value)\n",
    "    list_train_1_imag = cv2.GaussianBlur(train_layer[\"train_1_imag\"].reshape(60000,28,28), ksize=(3, 3), sigmaX=sigma_value)\n",
    "    list_train_2_real = cv2.GaussianBlur(train_layer[\"train_2_real\"].reshape(60000,28,28), ksize=(3, 3), sigmaX=sigma_value)\n",
    "    list_train_2_imag = cv2.GaussianBlur(train_layer[\"train_2_imag\"].reshape(60000,28,28), ksize=(3, 3), sigmaX=sigma_value)\n",
    "    list_train_3_real = cv2.GaussianBlur(train_layer[\"train_3_real\"].reshape(60000,28,28), ksize=(3, 3), sigmaX=sigma_value)\n",
    "    list_train_3_imag = cv2.GaussianBlur(train_layer[\"train_3_imag\"].reshape(60000,28,28), ksize=(3, 3), sigmaX=sigma_value)\n",
    "    list_train_4_real = cv2.GaussianBlur(train_layer[\"train_4_real\"].reshape(60000,28,28), ksize=(3, 3), sigmaX=sigma_value)\n",
    "    list_train_4_imag = cv2.GaussianBlur(train_layer[\"train_4_imag\"].reshape(60000,28,28), ksize=(3, 3), sigmaX=sigma_value)\n",
    "\n",
    "    # 結果を保存\n",
    "    diff_test_x_header = np.array(pd.DataFrame(diff_X_test).columns.tolist())\n",
    "    diff_test_y_header = np.array(pd.DataFrame(diff_y_test).columns.tolist())\n",
    "    diff_test_dst_header = np.array(pd.DataFrame(dst).columns.tolist())\n",
    "    np.savez('fashion_MNIST/X_diff_test', diff_test_x_header, diff_X_test)\n",
    "    np.savez('fashion_MNIST/y_diff_test', diff_test_y_header, diff_y_test)\n",
    "    np.savez('fashion_MNIST/dst_test', diff_test_dst_header, dst)\"\"\"\n",
    "\n",
    "    \"\"\"\n",
    "    # 保存\n",
    "    save_file_1 = 'second_gauss_train_0_real_ver2.pkl'\n",
    "    save_file_2 = 'second_gauss_train_1_real_ver2.pkl'\n",
    "    save_file_3 = 'second_gauss_train_1_imag_ver2.pkl'\n",
    "    save_file_4 = 'second_gauss_train_2_real_ver2.pkl'\n",
    "    save_file_5 = 'second_gauss_train_2_imag_ver2.pkl'\n",
    "    save_file_6 = 'second_gauss_train_3_real_ver2.pkl'\n",
    "    save_file_7 = 'second_gauss_train_3_imag_ver2.pkl'\n",
    "    save_file_8 = 'second_gauss_train_4_real_ver2.pkl'\n",
    "    save_file_9 = 'second_gauss_train_4_imag_ver2.pkl'\n",
    "\n",
    "    #　保存\n",
    "    f1 = open(save_file_1,\"wb\")\n",
    "    with open(save_file_1, 'wb') as f1:\n",
    "        pickle.dump(list_train_0_real,f1, -1)\n",
    "    ###\n",
    "    f2 = open(save_file_2,\"wb\")\n",
    "    with open(save_file_2, 'wb') as f2:\n",
    "        pickle.dump(list_train_1_real,f2, -1)\n",
    "    ### \n",
    "    f3 = open(save_file_3,\"wb\")\n",
    "    with open(save_file_3, 'wb') as f3:\n",
    "        pickle.dump(list_train_1_imag,f3, -1)\n",
    "    del list_train_1_imag\n",
    "    ###\n",
    "    f4 = open(save_file_4,\"wb\")\n",
    "    with open(save_file_4, 'wb') as f4:\n",
    "        pickle.dump(list_train_2_real,f4, -1)\n",
    "    del list_train_2_real\n",
    "    ###\n",
    "    f5 = open(save_file_5,\"wb\")\n",
    "    with open(save_file_5, 'wb') as f5:\n",
    "        pickle.dump(list_train_2_imag,f5, -1)\n",
    "    del list_train_2_imag\n",
    "    ###\n",
    "    f6 = open(save_file_6,\"wb\")\n",
    "    with open(save_file_6, 'wb') as f6:\n",
    "        pickle.dump(list_train_3_real,f6, -1)\n",
    "    del list_train_3_real\n",
    "    ###\n",
    "    f7 = open(save_file_7,\"wb\")\n",
    "    with open(save_file_7, 'wb') as f7:\n",
    "        pickle.dump(list_train_3_imag,f7, -1)\n",
    "    del list_train_3_imag\n",
    "    ###\n",
    "    f8 = open(save_file_8,\"wb\")\n",
    "    with open(save_file_8, 'wb') as f8:\n",
    "        pickle.dump(list_train_4_real,f8, -1)\n",
    "    del list_train_4_real\n",
    "    ###\n",
    "    f9 = open(save_file_9,\"wb\")\n",
    "    with open(save_file_9, 'wb') as f9:\n",
    "        pickle.dump(list_train_4_imag,f9, -1)\n",
    "    del list_train_4_imag\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "32fcd62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 60000, 784)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_gauss_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b3f1c67-6206-43b9-8811-d3ac70f94da7",
   "metadata": {
    "code_folding": [
     0
    ],
    "tags": []
   },
   "outputs": [],
   "source": [
    "#　テストデータ\n",
    "\"\"\"\n",
    "\n",
    "with open(\"test_four_coeff_layer_0_to_2_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_test_0_to_2 = pickle.load(f)\n",
    "with open(\"test_four_coeff_layer_3_to_4_ver2.pkl\",\"rb\") as f:\n",
    "    dataset_test_3_to_4 = pickle.load(f)\n",
    "    \n",
    "\n",
    "#dataset[\"X_train_val_first_gauss\"] = np.array([])\n",
    "second_gauss_test_0_to_2 = {}\n",
    "second_gauss_test_3_to_4 = {}\n",
    "\n",
    "import cv2\n",
    "#　ガウシアンぼかし\n",
    "second_gauss_test_0_to_2[\"test_0_real\"] = cv2.GaussianBlur(dataset_test_0_to_2[\"test_coeff_layer_0_real\"].reshape(10000,28,28), ksize=(3, 3), sigmaX=sigma_value)\n",
    "second_gauss_test_0_to_2[\"test_1_real\"] = cv2.GaussianBlur(dataset_test_0_to_2[\"test_coeff_layer_1_real\"].reshape(10000,28,28), ksize=(3, 3), sigmaX=sigma_value)\n",
    "second_gauss_test_0_to_2[\"test_1_imag\"] = cv2.GaussianBlur(dataset_test_0_to_2[\"test_coeff_layer_1_imag\"].reshape(10000,28,28), ksize=(3, 3), sigmaX=sigma_value)\n",
    "second_gauss_test_0_to_2[\"test_2_real\"] = cv2.GaussianBlur(dataset_test_0_to_2[\"test_coeff_layer_2_real\"].reshape(10000,28,28), ksize=(3, 3), sigmaX=sigma_value)\n",
    "second_gauss_test_0_to_2[\"test_2_imag\"] = cv2.GaussianBlur(dataset_test_0_to_2[\"test_coeff_layer_2_imag\"].reshape(10000,28,28), ksize=(3, 3), sigmaX=sigma_value)\n",
    "second_gauss_test_3_to_4[\"test_3_real\"] = cv2.GaussianBlur(dataset_test_3_to_4[\"test_coeff_layer_3_real\"].reshape(10000,28,28), ksize=(3, 3), sigmaX=sigma_value)\n",
    "second_gauss_test_3_to_4[\"test_3_imag\"] = cv2.GaussianBlur(dataset_test_3_to_4[\"test_coeff_layer_3_imag\"].reshape(10000,28,28), ksize=(3, 3), sigmaX=sigma_value)\n",
    "second_gauss_test_3_to_4[\"test_4_real\"] = cv2.GaussianBlur(dataset_test_3_to_4[\"test_coeff_layer_4_real\"].reshape(10000,28,28), ksize=(3, 3), sigmaX=sigma_value)\n",
    "second_gauss_test_3_to_4[\"test_4_imag\"] = cv2.GaussianBlur(dataset_test_3_to_4[\"test_coeff_layer_4_imag\"].reshape(10000,28,28), ksize=(3, 3), sigmaX=sigma_value)\n",
    "\n",
    "# 保存\n",
    "save_file = 'second_gauss_test_0_to_2_ver2.pkl'\n",
    "with open(save_file, 'wb') as f:\n",
    "    pickle.dump(second_gauss_test_0_to_2,f, -1)\n",
    "    \n",
    "save_file = 'second_gauss_test_3_to_4_ver2.pkl'\n",
    "with open(save_file, 'wb') as f:\n",
    "    pickle.dump(second_gauss_test_3_to_4,f, -1)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e630549d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71ece995",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABmUlEQVR4nJ2SS3PTQBCEZ1+SvHpEgpDEIXGFKooz//9/cOAiiuBUcJnIttDDq9XscIgcrwkn9jb71Ux1dzXA/z7218gZI+f+BZmMi1TtN9ueXkGu391camXX5bIjAAB5XIuy97dFooRI1fhjOIEsmS+u8zAgstllu6ucD2c3n+Zp4Oo2xDy+OP9tAIBPTOR389TZ/fbJMAZBrvyz4s1FaG3w8+t68dHKIZSMjlClEjh7+lLapAv1MMk/SE1HgWa5bBHRIpIPRZYK3jerhkDIQMhn+9NZlccB9u1uBBZIrRT5IchYxkJ2HQEPuXbKjvQCmZCkGDMDsShBV9t6PG4SWsc5WgsizzVr2631BI2DI0ACFl1lKdq6oROICE4I+fZaZyg2ex+SwXpwena2KCI0dYW+FdoPfTIrboMPeTjUy2r0oWuaZNTqMxQS2tVDfxIfdb9AxTyOIbDrb9VUokPwZnV1VmSS+PBYPk65v0CsypBpw8Z1+f3Zh98E88DNuXT1/f320EyvfWyWF9Gw23QIryEwKTiN6I4/fwA2y8NuKUNURQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABu0lEQVR4nLXSyXLaQBAG4J6RBu0LYjHEgLGTCsZ5/2dJZJsYOSFESDYCydommslBgC1XrulLV/V36K6uH+C/FPrnFCNgvIEIY84YAGDZ1stoz96goDtq9hxXIBqjcSf2HvZMPJrYuxjpO8/bkc70yjRStEtOKPaur3Qsc6o5Fx+UWGg5BoYDku58piVVqysw22Srbd8pS35A0p/NpY2PHWMIPFqHtsrDqKoR2x8/Sd5j1UlLSYwew/ZQ970dq7HVn2jBmhm6SspgFSrTs+R+lQGIAICUrlGk2sBQUF5hqT0Y0+/LhNcICHGp35YpxabzlNvT1sP9toID0tAfkMKPmE1Epre1za1fwgF5uhYKMfQTS0YZtaz97SqHI0IV0QCnqdYbkS2xi8Uy5q8IVZwANqYzNWE2W9YLAQDXjTOuXc6tl9IUft4FFBoISJtcnxWZSn67vwpoIlLHX4Z5JMvP336kvIlIGd0Mi51qxK6XnKxGpIxuJixR7NRd7NlrNkQAAGn4+ZwmxMzcu+OhJxSs84mZWyR33fCt1Y/HkgAiihdfgz/wHnmxhrZUrJYb2jDAAFC9xAWim/XTO4O/zjDO/7XvHzMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA2ElEQVR4nH2STW/CMAyG7dS1RqAqt2nSLvz/v7XBBQnWEUGdD++2JsjFN+vR4yR+A/CisO0QVFcg7rZ4C8WEuPt8h+Pp9u9SBd3+45DyFEyI4zDeB78MczXkXOb6nBoCqCroGnx6WTPWYe21sO+zhBTVgsic53tJtkmEJa/dNqaOPfUmVJGOvSN7CUmAGNE0QZODt45tUwWF0JMNIwRVv6jN+opKVO5NE4g23OW89BVDdgPRQ+ywifYRf8U0yzRd5/O12PDyrfFrWlJp0nXjVn/CCnz+1C/rD27MWCAjilKwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABNUlEQVR4nH3Q207CQBAG4H96IFALLCXQRKQCJfH934dDFZSK2CotBXtaLxAC28pc7reZmX+AG0VlbwTO/0G1XsuCiJdipdM3dks34oAimtJ5emCbLNiXoNQa2w212VABQBJ20fpDRnG8O/AiquaIgfPQ3RVRbo+7ck5bx/0BhJkSsy0N2DlOwMWZdGeNGEnx29TLIaJq2gaQbybvCUSU2dCgJPemywNEpFq/p0sUPjshL6BqDlsqxaupn0FEuW23FcCbrOPz/1MUqTmydEr92eseBaz2BozyYPGX8KqtYgwYIfs8JbxEqg+6FWT+fJ2igNV7q1nh4csi4gVUjEemUPIx+7psekTSzK6uZd5snVzZcVuSOY9W8/PZrjD1nChz59+5gAQApLX0xN+mKEOQRDznot2uX7fSf0LbKBkkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABNElEQVR4nK2SS2/CMBCEZ/2ICSCIKCqoqP//V1XqBdSCCuWR1HZsbw+FQCDH7m39edYztoH/KhJ007SZGOl0qLuhKBZFudxeqGo2MYBs+jzf1mXgW0jGwDmGHJtRVZiypTSTqfjeVBDaWqsEbiENZvN8LVc2Bia6+jiPzUdPfWU/pZYEQdQ601e+HqcYMTCKrgEUAHC5nhR5gRwLVsa3IeJuNejrIhPGkTkyt3Paj2H+MhiSd3WDGsiHd4WZFOlHXKc2N5R2b8H2U0FKSN12CyB+uc1YvWa9odV0pwTSsVxqtdB9nT1CcAR5ilL0VPhbEbgt9lxxyi9z76CNpxQyiU7o/Mk7cCdEqAPHELlTmZIxefNmd0q3jz4dwmMUAOw2ptrv0rm9+5qUFdrvPXdCkBTp4ge/GrmJQ/2LE30AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABqklEQVR4nLXRXW/aMBQG4GPHNvmiaWBRCW3F2q2s///HdNJUrZSGEipoICRxnDj2LviK2G7nSz96j63zAvyXg84vMEaglfoXGlbXswy+WXOlzxCbfjjwKJHreJbkuo2o44U3fUqpoWoRvbznmpzMCUdDxwSiRKm7o3pbnBC7o++BY7A0gTotQ79vIzig4X19DJhuNsL0RZnyrqz1AUnv28OVUQtQJpQJv+ipda4B73K9h/GANIiaGCDPO0N7Ncv2SeSO7gO5NRkpKpVmNHA/fn9UsEMSjPwstcyyaWQ8c+/9z58vqd4hsgeXfMmtwrrQ2VJ/6WdPz6mCPTq+sZ6p0HZr7YYQqOkkVQCHsYS5AfWZoDbVzEqm693iCQAAX/lOqGgtFWtcIqJ5BUdU24iFrFpt6G0NWC9fd0P3STEXcYdn5g8LsLGdLCS0UPN4icC5HVBpiOiN6zYCNA1yhnd2jVEySZpjGYfC7OvxpdQknxx+c0JkhuMrJVkVveb6iMdWbq7dBtXx86eEc0TEYhgV8a+5gL9Q8/fGMzbTt0K3cP+mzHKJ88UiVy2DPyzD0hhq4rvvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABV0lEQVR4nJ2Sy47TQBBFb5fL7jiJYxwvkAY0PP7/m2A2QwABechj97tYkFi2CRt601IfVZ3qqwL+96i/HgiS/gGparg7WQEA8KJu9/7d6vD0zc6hUhBB1jx+KNlcnEwhrdcYXhK3bZlvmkJNIdVvXsfDoWMNF1yKU6faPH58MLkxeYEMZN0M1m/bDe23VBQhhNh7TGFZpb7nDHnujfU2XmV/rhRdSEopJu/64GUK5aXPym2mmZkk3ua5waEjFKpq2rpi8lfl1SnmkoxOD7zXJubXCMZ/xkvPmWwVX0B5CLO2iOcTmNJ25XpREMygdF86vGJnpVyNbMzWfa1Q+rCrtXbBL2A6fxpaipyXELsYCAi/hmfa71WyY3o3J4DQ/TxRocUMfVq0BSCA1pz8qFysSUS9cudbtHMYj99LMmd7tzIdP6fdj+fu/mqqdaOHo5G7EJRRCmNCvwFuYa8nhCYicgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABjUlEQVR4nLXQb4+aQBAG8Jnln8AKHOoZT+1d27v2+3+bpknV2AbbqiACIrC70xemueX6uvNu8sszmTwA/2Xw7Y6IQIr+RTTMgcddlWcl9RGZw6NwyPkA9+tNSQBg/jXDv5uOI9dEQN+j80VqaMTvHmMDgKq8WY7vA6YhDpcfRxZQcToerChsWwIN/dnSr6uyapQ/mbZJpjQE6qouN6Pxb8ues9X6pCMV39ki8MVF8lBtv+xa0JPN+aKgKopmYh+//riChuiMlzNHlr/2Voii7UhHe/r85Dd5KSJTST5Lb//cEPl8EdZXFk1MJcxgvjvr6EShXTseCuA1gBcw/aw4p5KwOp0GH0yrAYYaqjJhI3k+pPKx5khNJfVk/bNyRVnjwyK0ZJdlPaTLFYmMyfO9xajY3vp5LUEBmPGn9z7IYps00ENEZsQvnwNh1Lt1rnrIXD7kD3Pe2SpbHQToiF4cuvbQdVCmq+QKPQR049Egtkkcv20KeoOq2hfkBWGXbFIJfaSmUYHvm+KwS7tXgz+SaMD2IXNA5wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABlElEQVR4nLWR226bUBBF9+EcsAFjQ0yTyCK9WI36//+TRI5V2SGpIb5A4NymD8aXtn7tPM7S2hrNBv7LsEtLh8HSZcj8OJTlzp4g58wYAgAW3n35tH6ebQhiz9w4EeuiIQC9yY/JaOTsPmQHRfot8xazRQPwZHqH2k2TZQdZkE2vHa630rIgy/DKrowB4ACAE2ex0aOxD4j0c1CpkJelwt50x7GpmNco5o6/T6yMovJ5pfeQBYnQxJuijcbTe7Z1h83DvKIO+iGMIyRuxpMb551imj2tLbpYIaAVD74iCtpSp2zxuNI4QCmFXsskspS/Npm/eXxR+zcCoLrQw8QxvX6b515s5vOKzuByqePEJc3c9Norfm7s/m8CAPTbA90K2/ZDkgNbrBTOINXzOh9xc3XrhaSKLrSDoI/Fqufw+2Hf21XFQTy0QlrXbCBYwOvNxhxLP3ZMCAbElHnf0V8mAIh4iLZVlca/JvjAd4w00uKCCaIosOvjrX+Ypnxr1S7fXjT1rycZvsxP95xDW6/8bVGq0+Y33zrMl1TTnj0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABWklEQVR4nLXSSVPCQBAF4O7JZCGQxRJQUcoSKf//f/GoZSmKiqzZSDKZmfYgFoN69R3fV/X60gD/EvxVICPSf6PdDn2ZZ7Um+ono9i56rkqXaVUW9Q/0BuN+G6AuVLmazgU3jXdH15GW2vMb3cFqbSIGw7N4WwqLSyd01wxNdHonUaPcgFUE1XIlyEBsdR2V2FaBLITF5CVTJnqBaPIz4gzV7O5ho+DgJjBR1K7TZPP751SDgawVH7UaTlyupw9vpYY9oh0NRnEjXKo/Hp9WgmCPvN2/PI1YWkdsefuSq10LAIBOdziMO7xWzM0mk5zAQHcwHsaMJcBiKjPxbcABwO7fXHWa1GKBZVfye/MLsXN+4S0S1tKCB9km0QfohT7jPknb87ezaXaAINN5qC0JTZKsHt9qMFHnr3TskJSE+ey9oD0iAKDX9i0kALndVobtPgERAQCITPq3fAI1RKiDWnSASgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#img = second_gauss_test[0][4].reshape(28,28)*128\n",
    "k = 1000\n",
    "for i in range(k,k+10):\n",
    "    img = cv2.GaussianBlur(list_train_four_coeff[0][i].reshape(28,28), ksize=(3, 3), sigmaX=10)*4\n",
    "    Image.fromarray(img).show()\n",
    "#img_gaussian = cv2.imread(osp.join(HOME, \"研究/MNIST/Training_Images/First_Gaussian_Images/{}.png\".format(str(3).zfill(5))),cv2.COLOR_BGR2RGB)\n",
    "#cv2.imshow(\"a\",img)\n",
    "\n",
    "#img_np = np.array(img)\n",
    "#img_gaussian_np = np.array(img_gaussian)\n",
    "\n",
    "#img_resize = cv2.resize(img, (28,28))\n",
    "#img_gaussian_resize = cv2.resize(img_gaussian, (256,256))\n",
    "#img_np = np.array(img_resize)\n",
    "#img_gaussian_np = np.array(img_gaussian_resize)\n",
    "#Image.fromarray(img).show()\n",
    "#Image.fromarray(img_gaussian_resize).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "b6e0faa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 60000, 784)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_train_four_coeff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3994b740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_resize.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "71afde3b",
   "metadata": {
    "code_folding": [
     0,
     15
    ],
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0  10  57  57  57  57    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    4 146 241 240 240 240 240 243 254 254 243 225    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0  21 222 183 183 183 183 183 113 113  78  26    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    3  34    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0 121 216    5    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0  85 229 107    3    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0  83 246 134    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0  16 235 248 169 141  67    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0  56 200 161 141 177 252 156  12    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0 110 251  91    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0  15 233  91    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0  76 242  24    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0 213 103    0    0    0    0    0  16 213 234    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0 243 255 168  38    0    0  54 199 250 114    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0 103 241 254 251 226 207 243 247  76    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0  35  56  56  56  57  56  28    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    1    5    6    6    5    1    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    2  15  24  25  25  25  26  37  68  72  71  62    7    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    1  19 132 202 209 209 209 208 207 217 214 200 166  19    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    1    5  34 170 172 170 170 170 164 121 113  87  48  24    3    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    2  17  41  10  21  20  19  19  19  19  13  12    8    3    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    1  20 115 159  23    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    1  17  96 185 107  14    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0  11  96 206 143  37    9    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    2  37 197 228 167 128  78  21    3    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    5  55 165 154 134 158 204 143  31    2    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    1    7  19  17  15  28 118 209  90    9    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    3  50 198  91    9    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    2  19  11    1    0    0    0    0  10  92 201  48    3    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0  20 164 108  26    5    0    1    8  48 187 197  25    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0  24 203 228 157  64  27  27  76 177 211 114  12    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0  11 108 209 222 207 185 175 201 203  92  19    1    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    1  14  50  69  70  68  67  67  46  11    1    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    4    6    6    6    6    6    3    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'print(img.shape)\\nprint(img_gaussian.shape)'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for i in range(28):\n",
    "    for j in range(28):\n",
    "        #print(\"普通の画像\")\n",
    "        if (img[i][j]<10):\n",
    "            print(\"    \",end=\"\")\n",
    "            print(img[i][j], end=\"\")\n",
    "        elif (img[i][j]<100):\n",
    "            print(\"  \",end=\"\")\n",
    "            print(img[i][j],end=\"\")\n",
    "        else:\n",
    "            print(\" \",end=\"\")\n",
    "            print(img[i][j],end=\"\")\n",
    "    print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "for i in range(28):\n",
    "    for j in range(28):\n",
    "        #print(\"普通の画像\")\n",
    "        if (img_gaussian[i][j]<10):\n",
    "            print(\"    \",end=\"\")\n",
    "            print(img_gaussian[i][j], end=\"\")\n",
    "        elif (img_gaussian[i][j]<100):\n",
    "            print(\"  \",end=\"\")\n",
    "            print(img_gaussian[i][j],end=\"\")\n",
    "        else:\n",
    "            print(\" \",end=\"\")\n",
    "            print(img_gaussian[i][j],end=\"\")\n",
    "    print(\"\")\n",
    "print(img.shape)\n",
    "print(img_gaussian.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba172e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yy/y.shinozaki/研究/MNIST/MNIST_pickle\n"
     ]
    }
   ],
   "source": [
    "cd MNIST_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b20a305",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# MNIST 複数チャンネル用(Pytorch)\n",
    "\n",
    "from tensorflow.keras.layers import Flatten\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy as sp\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import torch\n",
    "\n",
    "with open(\"second_gauss_train_0_to_2.pkl\",\"rb\") as f:\n",
    "    dataset_train_0_to_2 = pickle.load(f)\n",
    "with open(\"second_gauss_train_3_to_4.pkl\",\"rb\") as f:\n",
    "    dataset_train_3_to_4 = pickle.load(f)\n",
    "with open(\"second_gauss_test.pkl\",\"rb\") as f:\n",
    "    dataset_test = pickle.load(f)\n",
    "with open(\"raw_mnist.pkl\",\"rb\") as f:\n",
    "    dataset_raw = pickle.load(f)\n",
    "\n",
    "# Kerasに付属の手書き数字画像データをダウンロード\n",
    "labels_train_base = dataset_raw[\"y_train\"]\n",
    "\n",
    "#X_train_base = dataset_train_0_to_2[\"second_gauss_train_0_to_2\"][2]\n",
    "X_train_base = np.vstack((dataset_train_0_to_2[\"second_gauss_train_0_to_2\"],dataset_train_3_to_4[\"second_gauss_train_3_to_4\"]))\n",
    "#X_train_base = X_train_base      \n",
    "    \n",
    "X_test = dataset_test[\"second_gauss_test\"]\n",
    "X_test = X_test.reshape(9,10000,784)\n",
    "X_test = X_test.transpose(1,0,2)\n",
    "labels_test = dataset_raw[\"y_test\"]\n",
    "# 軸を交換\n",
    "X_train_base = X_train_base.transpose(1,0,2)\n",
    "labels_test_9 = labels_test\n",
    "labels_train_9 = labels_train_base\n",
    "#X_train_loader = torch.utils.data.DataLoader(dataset=X_train_base, batch_size=10000, shuffle=True)\n",
    "# Training set を学習データ（X_train, labels_train）と検証データ（X_validation, labels_validation）に8:2で分割する\n",
    "X_train,X_validation,labels_train,labels_validation = train_test_split(X_train_base,labels_train_base,test_size = 0.2) \n",
    "# 各画像は行列なので1次元に変換→X_train,X_validation,X_testを上書き\n",
    "\n",
    "#正規化 (行ごとの正規化)\n",
    "X_train = X_train.astype('float32')\n",
    "X_validation = X_validation.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = sp.stats.zscore(X_train,axis=1)\n",
    "X_validation = sp.stats.zscore(X_validation,axis=1)\n",
    "X_test = sp.stats.zscore(X_test,axis=1)\n",
    "# labels_train, labels_validation, labels_test をダミー変数化して y_train, y_validation, y_test に格納する\n",
    "y_train = to_categorical(labels_train)\n",
    "y_validation = to_categorical(labels_validation)\n",
    "y_test = to_categorical(labels_test)\n",
    "\n",
    "# dataloader作成\n",
    "X_train_loader = torch.utils.data.DataLoader(dataset=X_train, batch_size=100, shuffle=False)\n",
    "X_validation_loader = torch.utils.data.DataLoader(dataset=X_validation, batch_size=100, shuffle=False)\n",
    "X_test_loader = torch.utils.data.DataLoader(dataset=X_test, batch_size=100, shuffle=False)\n",
    "y_train_loader = torch.utils.data.DataLoader(dataset=y_train, batch_size=100, shuffle=False)\n",
    "y_validation_loader = torch.utils.data.DataLoader(dataset=y_validation, batch_size=100, shuffle=False)\n",
    "y_test_loader = torch.utils.data.DataLoader(dataset=y_test, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69efda95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (48000, 9, 784)\n",
      "X_tvalidation: (12000, 9, 784)\n",
      "X_test: (10000, 9, 784)\n",
      "y_train: (48000, 10)\n",
      "y_validation: (12000, 10)\n",
      "y_test: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train:\",X_train.shape)\n",
    "print(\"X_tvalidation:\",X_validation.shape)\n",
    "print(\"X_test:\",X_test.shape)\n",
    "print(\"y_train:\",y_train.shape)\n",
    "print(\"y_validation:\",y_validation.shape)\n",
    "print(\"y_test:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c18d410",
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10, Loss: 0.662894287109375 ,Time 2022-11-14 12:05:11.590052+09:00\n",
      "Epoch: 2/10, Loss: 0.2668366495768229 ,Time 2022-11-14 12:05:15.259570+09:00\n",
      "Epoch: 3/10, Loss: 0.20937152862548827 ,Time 2022-11-14 12:05:19.162526+09:00\n",
      "Epoch: 4/10, Loss: 0.17454419453938802 ,Time 2022-11-14 12:05:22.735976+09:00\n",
      "Epoch: 5/10, Loss: 0.14961835225423178 ,Time 2022-11-14 12:05:26.296329+09:00\n",
      "Epoch: 6/10, Loss: 0.1300244394938151 ,Time 2022-11-14 12:05:29.960918+09:00\n",
      "Epoch: 7/10, Loss: 0.11467575073242188 ,Time 2022-11-14 12:05:33.535177+09:00\n",
      "Epoch: 8/10, Loss: 0.10197804768880209 ,Time 2022-11-14 12:05:37.130389+09:00\n",
      "Epoch: 9/10, Loss: 0.09095195770263671 ,Time 2022-11-14 12:05:40.677206+09:00\n",
      "Epoch: 10/10, Loss: 0.08188023885091146 ,Time 2022-11-14 12:05:44.360704+09:00\n",
      "Loss: 0.10393674850463867, Accuracy: 96.83% (9683/10000)\n"
     ]
    }
   ],
   "source": [
    "# Keras　ニューラルネットワーク\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# ハイパーパラメータなどの設定値\n",
    "num_epochs = 10         # 学習を繰り返す回数\n",
    "num_batch = 100         # 一度に処理する画像の枚数\n",
    "learning_rate = 0.001   # 学習率\n",
    "image_size = 28*28      # 画像の画素数(幅x高さ)\n",
    "\n",
    "# GPU(CUDA)が使えるかどうか？\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# 学習用／評価用のデータセットの作成\n",
    "\n",
    "# 変換方法の指定\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "# MNISTデータの取得\n",
    "# https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST\n",
    "# 学習用\n",
    "train_dataset = datasets.MNIST(\n",
    "    './data',               # データの保存先\n",
    "    train = True,           # 学習用データを取得する\n",
    "    download = True,        # データが無い時にダウンロードする\n",
    "    transform = transform   # テンソルへの変換など\n",
    "    )\n",
    "# 評価用\n",
    "test_dataset = datasets.MNIST(\n",
    "    './data', \n",
    "    train = False,\n",
    "    transform = transform\n",
    "    )\n",
    "\n",
    "\n",
    "# データローダー\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = num_batch,\n",
    "    shuffle = True)\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,     \n",
    "    batch_size = num_batch,\n",
    "    shuffle = True)\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# ニューラルネットワークモデルの定義\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # 各クラスのインスタンス（入出力サイズなどの設定）\n",
    "        self.fc1 = nn.Linear(input_size, 100)\n",
    "        self.fc2 = nn.Linear(100, output_size)\n",
    "        #self.fc3 = nn.Linear(output_size, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 順伝播の設定（インスタンスしたクラスの特殊メソッド(__call__)を実行）\n",
    "        x = self.fc1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# ニューラルネットワークの生成\n",
    "model = Net(image_size, 10).to(device)\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# 損失関数の設定\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "#----------------------------------------------------------\n",
    "# 最適化手法の設定\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate) \n",
    "\n",
    "#----------------------------------------------------------\n",
    "# 学習\n",
    "model.train()  # モデルを訓練モードにする\n",
    "\n",
    "for epoch in range(num_epochs): # 学習を繰り返し行う\n",
    "    loss_sum = 0\n",
    "\n",
    "    #for inputs, labels in X_train_loader, y_train_loader:\n",
    "    for inputs, labels in train_dataloader:\n",
    "        \n",
    "        # GPUが使えるならGPUにデータを送る\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # optimizerを初期化\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # ニューラルネットワークの処理を行う\n",
    "        inputs = inputs.view(-1, image_size) # 画像データ部分を一次元へ並び変える\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # 損失(出力とラベルとの誤差)の計算\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_sum += loss\n",
    "\n",
    "        # 勾配の計算\n",
    "        loss.backward()\n",
    "\n",
    "        # 重みの更新\n",
    "        optimizer.step()\n",
    "\n",
    "    #　現在時刻の取得\n",
    "    #now = time.strftime(\"%Y%m%d %H:%M:%S\")\n",
    "    now = datetime.now(ZoneInfo(\"Asia/Tokyo\"))\n",
    "    \n",
    "    # 学習状況の表示\n",
    "    print(f\"Epoch: {epoch+1}/{num_epochs}, Loss: {loss_sum.item() / len(train_dataloader)}\", end=\" \")\n",
    "    print(\",Time\",now)\n",
    "    # モデルの重みの保存\n",
    "    torch.save(model.state_dict(), 'model_weights.pth')\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# 評価\n",
    "model.eval()  # モデルを評価モードにする\n",
    "\n",
    "loss_sum = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "\n",
    "        # GPUが使えるならGPUにデータを送る\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # ニューラルネットワークの処理を行う\n",
    "        inputs = inputs.view(-1, image_size) # 画像データ部分を一次元へ並び変える\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # 損失(出力とラベルとの誤差)の計算\n",
    "        loss_sum += criterion(outputs, labels)\n",
    "\n",
    "        # 正解の値を取得\n",
    "        pred = outputs.argmax(1)\n",
    "        # 正解数をカウント\n",
    "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "\n",
    "print(f\"Loss: {loss_sum.item() / len(test_dataloader)}, Accuracy: {100*correct/len(test_dataset)}% ({correct}/{len(test_dataset)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c9fb8d",
   "metadata": {},
   "source": [
    "---\n",
    "(MNIST)[ https://exture-ri.com/2021/01/11/pytorch-cnn/ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "73b6465e",
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to mydata/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0fca77e6b1d4fb196baabd4b55f19d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mydata/MNIST/raw/train-images-idx3-ubyte.gz to mydata/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to mydata/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13183c6ee2a049b7a662ce909654ef38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mydata/MNIST/raw/train-labels-idx1-ubyte.gz to mydata/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to mydata/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce7c27f686241b2ab3e575d226d5ded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mydata/MNIST/raw/t10k-images-idx3-ubyte.gz to mydata/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to mydata/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0417bfcf1d9244a886b6bfb8a812a482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mydata/MNIST/raw/t10k-labels-idx1-ubyte.gz to mydata/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ライブラリの準備\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "'''Datasetの準備'''\n",
    "train_dataset = MNIST(root='mydata', train=True,  transform=transforms.ToTensor(), download=True)\n",
    "test_dataset  = MNIST(root='mydata', train=False, transform=transforms.ToTensor())\n",
    "\n",
    "'''DataLoaderを作成'''\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)\n",
    "test_loader  = DataLoader(dataset=test_dataset,  batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cd03e013",
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "# モデルと最適化手法の定義の定義\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.fc = nn.Linear(7 * 7 * 32, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CNN().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "326be4f2",
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "#訓練用の関数を定義\n",
    "def train(train_loader):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss = running_loss / len(train_loader) \n",
    "    return train_loss\n",
    "\n",
    "'''評価用の関数を定義'''\n",
    "def valid(test_loader):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            predicted = outputs.max(1, keepdim=True)[1]\n",
    "            labels = labels.view_as(predicted)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    val_loss = running_loss / len(test_loader)\n",
    "    val_acc = correct / total\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9d247336",
   "metadata": {
    "code_folding": [
     0,
     6
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_733668/667516088.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch %d, loss: %.4f val_loss: %.4f val_acc: %.4f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mloss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mval_loss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_acc' is not defined"
     ]
    }
   ],
   "source": [
    "#誤差(loss)を記録する空の配列を用意\n",
    "loss_list = []\n",
    "val_loss_list = []\n",
    "val_acc_list = []\n",
    "\n",
    "'''学習'''\n",
    "for epoch in range(10):\n",
    "    loss = train(train_loader)\n",
    "    val_loss, val_acc = valid(test_loader)\n",
    "    print('epoch %d, loss: %.4f val_loss: %.4f val_acc: %.4f' % (epoch, loss, val_loss, val_acc))\n",
    "    loss_list.append(loss)\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_acc_list.append(val_acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
